{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ba8657-0360-477b-ac3d-cb3adbb1f199",
   "metadata": {},
   "source": [
    "### Dissertation Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f0fd0-f8d0-4f40-b861-d9077a850d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "def get_moved(x, col = 'bus_prox_class'):\n",
    "    if not x['moved']:\n",
    "        return False, False, False\n",
    "    else:\n",
    "        if pd.isna(x[f'prev_{col}']):\n",
    "            return True, False, False\n",
    "        else:\n",
    "            if x[f'prev_{col}'] < x[col]:\n",
    "                if col == 'prox_class':\n",
    "                    return False, True, False\n",
    "                else:\n",
    "                    return True, False, False\n",
    "            elif x[f'prev_{col}'] > x[col]:\n",
    "                if col == 'prox_class':\n",
    "                    return True, False, False\n",
    "                else:\n",
    "                    return False, True, False\n",
    "            else:\n",
    "                return False, False, True\n",
    "\n",
    "def get_moved_within(x, col = 'oa21cd'):\n",
    "    if not x['moved']:\n",
    "        return False\n",
    "    else:\n",
    "        if pd.isna(x[f'prev_{col}']):\n",
    "            return False\n",
    "        else:\n",
    "            if x[f'prev_{col}'] == x[col]:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "def get_status_date(x, df):\n",
    "    if pd.isna(x['status_date']):\n",
    "        tmp = df[(df['rates_code'] == x['rates_code']) & (df['location_code'] == x['location_code'])].copy()\n",
    "        if len(tmp):\n",
    "            return tmp['status_date'].iloc[0]\n",
    "        else:\n",
    "            if pd.isna(x['occupation_date']):\n",
    "                return x['from_date']\n",
    "            else:\n",
    "                return x['occupation_date']\n",
    "    else:\n",
    "        return x['status_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57a4ba-c6f5-4249-9a42-7117b8b8ce86",
   "metadata": {},
   "source": [
    "# Preprocess Business Rate Data and Clean wrong Postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0722ae9-ef32-4dbd-86e3-72cc4841ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data files \n",
    "# use glob to get all the CSV files in the folder\n",
    "path_lambeth = 'Data\\\\business rate data\\\\Lambeth\\\\'\n",
    "csv_files = []\n",
    "csv_files.extend(glob.glob(os.path.join(path_lambeth, \"*.csv\")))\n",
    "\n",
    "path_southwark = 'Data\\\\business rate data\\\\Southwark\\\\'\n",
    "csv_files.extend(glob.glob(os.path.join(path_southwark, \"*.csv\")))\n",
    "\n",
    "excel_files = glob.glob(os.path.join(path_southwark, \"*.xlsx\"))\n",
    "\n",
    "# loop over the list of CSV files\n",
    "wands_br_df= []\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    df['quarter']= f.split(\"\\\\\")[-1][:7]\n",
    "    wands_br_df.append(df)\n",
    "\n",
    "for f in excel_files:\n",
    "    df = pd.read_excel(f)\n",
    "    df['quarter']= f.split(\"\\\\\")[-1][:7]\n",
    "    wands_br_df.append(df)\n",
    "# Dataframe concatenation\n",
    "wands_br_df= pd.concat(wands_br_df, ignore_index=True)\n",
    "\n",
    "wands_br_2024_df = pd.concat([pd.read_csv(\"Data\\\\business rate data\\\\alswliman\\\\period-2021-to-2024-E09000022-lambeth.csv\"),\n",
    "                              pd.read_csv(\"Data\\\\business rate data\\\\alswliman\\\\period-2021-to-2024-E09000028-southwark.csv\")],\n",
    "                            ignore_index = True)\n",
    "wands_br_2024_df = wands_br_2024_df.rename(columns = {'filter_period' : 'period', 'billing_authority_name' : 'rates_authority',\n",
    "                     'geocode' : 'rates_authority_id', 'uarn' : 'location_code', 'billing_reference' : 'rates_code',\n",
    "                     'account_name' : 'name', 'account_start_date' : 'status_date', 'searchable_address' : 'address_street',\n",
    "                     'postcode_id' : 'pc__pcs', 'category_id' : 'scat_code', 'primary_description' : 'use_category',\n",
    "                     'category_subgroup' : 'sub_category', 'category_group' : 'category', 'rates_payable' : 'rates_expected',\n",
    "                     'rateable_value' : 'rental_valuation', 'total_floor_area' : 'floor_area'})\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = ['geometry', 'occupation_state', 'unit_of_measure', 'series', 'epoch'])\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['period'] = wands_br_2024_df['period'].apply(lambda x: '-'.join([x.split('-')[0], x.split('-')[1]]))\n",
    "wands_br_2024_df['quarter'] = wands_br_2024_df['period']\n",
    "wands_br_2024_df = wands_br_2024_df[wands_br_2024_df['period'].apply(lambda x: int(x.split('-')[1])) == 12].copy()\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.groupby(['rates_code', 'location_code'])['status_date'].ffill()\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.groupby(['rates_code', 'location_code'])['status_date'].bfill()\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_2024_df[wands_br_2024_df['status_date'].apply(pd.isna)].shape)\n",
    "wands_br_rates_code_df = wands_br_df[['rates_code', 'location_code', 'name', 'status_date'\n",
    "                                     ]].rename(columns = {'status_date' : 'old_status_date'})\n",
    "wands_br_rates_code_df['old_status_date'] = wands_br_rates_code_df['old_status_date'].apply(\n",
    "    lambda x: str(parse(x)).split(' ')[0] if isinstance(x, str) else str(x).split(' ')[0])\n",
    "wands_br_rates_code_df = wands_br_rates_code_df.drop_duplicates()\n",
    "wands_br_rates_code_df = wands_br_rates_code_df.groupby(['rates_code', 'location_code', 'name']).min().reset_index()\n",
    "print(wands_br_rates_code_df.shape)\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df = wands_br_2024_df.set_index(['rates_code', 'location_code', 'name']).join(\n",
    "    wands_br_rates_code_df.set_index(['rates_code', 'location_code', 'name'])).reset_index()\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['old_status_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = ['old_status_date'])\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['occupation_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['from_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_2024_df[wands_br_2024_df['status_date'].apply(pd.isna)].shape)\n",
    "drop_cols = list(set(wands_br_2024_df.columns) - set(wands_br_df.columns))\n",
    "print(drop_cols)\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = drop_cols)\n",
    "ext_cols = list(set(wands_br_df.columns) - set(wands_br_2024_df.columns))\n",
    "print(ext_cols)\n",
    "for col in ext_cols:\n",
    "    wands_br_2024_df[col] = np.nan\n",
    "\n",
    "wands_br_df = pd.concat([wands_br_df, wands_br_2024_df[wands_br_df.columns]], ignore_index = True)\n",
    "print(wands_br_df.shape)\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_df.shape)\n",
    "wands_br_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70ca4e-6c48-46c0-bd8c-9667341135bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lon_lat_map_df = pd.read_csv(\"Data/ONSPD_MAY_2025_UK_SW.csv\")\n",
    "pc_lon_lat_map_df = pc_lon_lat_map_df[['pcd2', 'lat', 'long']]\n",
    "pc_lon_lat_map_df['pcd2'] = pc_lon_lat_map_df['pcd2'].apply(lambda x: ' '.join([x.split(' ')[0],\n",
    "                                                            x.split(' ')[-1]]))\n",
    "\n",
    "pc_lsoa_mapping_df = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\PCD_OA21_LSOA21.csv\", encoding = \"ISO-8859-1\")\n",
    "pc_lsoa_mapping_df = pc_lsoa_mapping_df[(pc_lsoa_mapping_df['ladnm'] == 'Lambeth') |\n",
    "                                        (pc_lsoa_mapping_df['ladnm'] == 'Southwark')].copy()\n",
    "pc_lsoa_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb13d73-c833-4d98-afaf-1eec898121f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_pc_mapping = {'SW12 0BP' : 'SW12 0BT', 'SW12 0AB' : 'SW12 0BT',\n",
    "'SW12 0HY' : 'SW12 0PJ', 'SW12 0NA' : 'SW12 0BS', 'SW12 0PH' : 'SW12 0PJ', 'SW12 0LT' : 'SW12 0BT',\n",
    "'SW12 0PQ' : 'SW12 0PJ', 'SW12 0PS' : 'SW12 0PL', 'SW17 0AY' : 'SW17 0AS',\n",
    "'SW17 0BH' : 'SW17 0BQ', 'SW4 0PT' : 'SW4 0QE', 'SW8 3LG' : 'SW8 3DJ'}\n",
    "wands_br_df['closest_pc'] = wands_br_df['pc__pcs'].apply(lambda x: x if x not in closest_pc_mapping\n",
    "                                                        else closest_pc_mapping[x])\n",
    "wands_br_lsoa_df = wands_br_df.set_index('closest_pc').join(pc_lsoa_mapping_df.rename(\n",
    "    columns = {'pcds' : 'closest_pc'}).set_index('closest_pc')[['oa21cd', 'lsoa21cd', 'msoa21cd']]).reset_index()\n",
    "wands_br_lsoa_df['year'] = wands_br_lsoa_df['quarter'].apply(lambda x: int(x.split('-')[0]))\n",
    "wands_br_lsoa_df['address_no'] = wands_br_lsoa_df['address_no'].fillna('')\n",
    "wands_br_lsoa_df['address_street'] = wands_br_lsoa_df['address_street'].fillna('')\n",
    "wands_br_lsoa_df['addressline1'] = wands_br_lsoa_df.apply(lambda x:\n",
    "                                  ' '.join([str(x['address_no']), x['address_street']]), axis = 1)\n",
    "wands_br_lsoa_df['addressline1_merge'] = wands_br_lsoa_df['addressline1'].fillna('').apply(\n",
    "    lambda x: re.sub(r'[^\\w\\s]','',x.lower()))\n",
    "\n",
    "#fix missing names\n",
    "br_cols = ['closest_pc', 'pc__pcs', 'rates_code', 'location_code', 'address_no',\n",
    "           'address_street', 'use_category', 'sub_category', 'category', 'rental_valuation',\n",
    "           'valuation_date', 'period', 'rates_expected', 'name', 'status', 'status_date', 'quarter']\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.sort_values(by = ['rates_code', 'period'])\n",
    "wands_br_lsoa_df['name'] = wands_br_lsoa_df['name'].bfill()\n",
    "\n",
    "#add min and mex periods\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('rates_code').join(wands_br_lsoa_df[['rates_code', 'period'\n",
    "        ]].groupby('rates_code').min().rename(columns = {'period' : 'min_period'})).reset_index()\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('rates_code').join(wands_br_lsoa_df[['rates_code', 'period'\n",
    "        ]].groupby('rates_code').max().rename(columns = {'period' : 'max_period'})).reset_index()\n",
    "\n",
    "#reduce business rate data to yearly\n",
    "wands_br_lsoa_df['quarter'] = wands_br_lsoa_df['quarter'].apply(lambda x: int(x.split('-')[1]))\n",
    "quarter_wands_br_lsoa_df = wands_br_lsoa_df.copy()\n",
    "wands_br_lsoa_df = wands_br_lsoa_df[(wands_br_lsoa_df['quarter'] == 12)].copy()\n",
    "\n",
    "#map post code to lon, lat\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('closest_pc').join(pc_lon_lat_map_df.rename(columns = {\n",
    "    'pcd2' : 'closest_pc'}).set_index('closest_pc')).reset_index()\n",
    "\n",
    "# add dissolutiondate and incorporationdate\n",
    "wands_br_lsoa_df['dissolutiondate'] = wands_br_lsoa_df['max_period'].apply(lambda x: np.nan\n",
    "                                                   if x == '2024-12' else x + '-01')\n",
    "wands_br_lsoa_df['incorporationdate'] = wands_br_lsoa_df['status_date']\n",
    "\n",
    "\n",
    "#identify moved businesses\n",
    "wands_br_lsoa_df['postcode'] = wands_br_lsoa_df['closest_pc']\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.sort_values(by = ['rates_code', 'year'])\n",
    "wands_br_lsoa_df['prev_postcode'] = wands_br_lsoa_df.groupby('rates_code')['postcode'].shift()\n",
    "wands_br_lsoa_df['moved'] = wands_br_lsoa_df.apply(lambda x:\n",
    "        ((x['prev_postcode'] != x['postcode']) and (not pd.isna(x['prev_postcode']))), axis = 1)\n",
    "\n",
    "#add company name and company id\n",
    "wands_br_lsoa_df['companyname'] = wands_br_lsoa_df['name']\n",
    "wands_br_lsoa_df['rates_code'] = wands_br_lsoa_df['rates_code'].apply(lambda x: str(int(float(x))) if 'E+' in str(x) else x)\n",
    "wands_br_lsoa_df['CompanyID'] = wands_br_lsoa_df['rates_code']\n",
    "\n",
    "#########################\n",
    "print(wands_br_lsoa_df.shape)\n",
    "t = wands_br_lsoa_df.fillna('').groupby(['year', 'CompanyID']).count().sort_values(by = 'companyname').reset_index()\n",
    "ids = t[t['companyname'] > 1]['CompanyID'].unique()\n",
    "wands_br_lsoa_df_tmp = wands_br_lsoa_df[wands_br_lsoa_df['CompanyID'].isin(ids)].copy()\n",
    "wands_br_lsoa_df_tmp['CompanyID'] = wands_br_lsoa_df_tmp.apply(lambda x: '-'.join([x['CompanyID'],\n",
    "                                                                       str(x['location_code']), x['name']]), axis = 1)\n",
    "wands_br_lsoa_df = pd.concat([wands_br_lsoa_df_tmp, wands_br_lsoa_df[~wands_br_lsoa_df['CompanyID'].isin(ids)]])\n",
    "print(wands_br_lsoa_df.shape)\n",
    "#########################\n",
    "\n",
    "#add scat categories and survived\n",
    "wands_br_lsoa_df['category'] = wands_br_lsoa_df.apply(lambda x: x['sub_category']\n",
    "                                  if pd.isna(x['category']) else x['category'], axis = 1)\n",
    "wands_br_lsoa_df['scat_sub_category'] = wands_br_lsoa_df['sub_category']\n",
    "wands_br_lsoa_df['scat_category'] = wands_br_lsoa_df['category']\n",
    "wands_br_lsoa_df['survived'] = wands_br_lsoa_df['dissolutiondate'].apply(lambda x: pd.isna(x))\n",
    "\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.rename(columns = {'rates_authority' : 'ladnm'})\n",
    "\n",
    "wands_br_lsoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9ef4a-650b-47e9-9cad-4256a3f91add",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = wands_br_lsoa_df.groupby(['CompanyID', 'companyname', 'year']).count()[['postcode']\n",
    "                    ].reset_index().groupby(['companyname', 'year']).count().reset_index()\n",
    "print(s[s['CompanyID'] > 1].shape)\n",
    "print(s[s['CompanyID'] == 1].shape)\n",
    "companies = s['companyname'].unique()\n",
    "non_uniq_companies = s[s['CompanyID'] != 1]['companyname'].unique()\n",
    "uniq_companies = list(set(companies) - set(non_uniq_companies))\n",
    "print(len(uniq_companies))\n",
    "print(len(non_uniq_companies))\n",
    "print(len(companies))\n",
    "print(wands_br_lsoa_df.shape)\n",
    "wands_br_lsoa_df = wands_br_lsoa_df[wands_br_lsoa_df['companyname'].isin(uniq_companies)]\n",
    "print(wands_br_lsoa_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37eabc-b47e-4b4e-b4c2-e63aee08752f",
   "metadata": {},
   "source": [
    "### Processing Business Census Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b044e5-5854-45c1-b331-f9574b8a9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Wandsworth ONS mapping data\n",
    "\n",
    "cols = ['CompanyID', 'CompanyNumber', 'CompanyName', 'CompanyStatus', 'PostCode',\n",
    "       'oa11', 'lsoa11', 'msoa11', 'oa21', 'lsoa21', 'msoa21', 'PostCodeLatitude', 'PostCodeLongitude']\n",
    "ons_df = pd.read_csv(\"Data\\Business Cencus CDRC\\entities\\\\ONSGeography.csv.zip\",\n",
    "                      compression='zip', usecols=cols)\n",
    "wands_ons_df = ons_df[ons_df['lsoa21'].isin(pc_lsoa_mapping_df['lsoa21cd'].unique())].copy()\n",
    "wands_ons_df.to_csv('Data\\Business Cencus CDRC\\entities\\lam_south_ONSGeography.csv', index = False)\n",
    "\n",
    "## Combine Business Census data with Wandsworth ONS data\n",
    "\n",
    "wands_year_census_df = []\n",
    "for i in range(13):\n",
    "    year = 2012 + i\n",
    "    census_df = pd.read_csv(f\"Data\\\\Business Cencus CDRC\\\\business_census{year}.csv.zip\", compression='zip')\n",
    "    census_df['data_year'] = year\n",
    "    tmp = census_df.rename(columns = {'id' : 'CompanyID'}).set_index('CompanyID').join(\n",
    "        wands_ons_df.set_index('CompanyID'), how = 'inner')\n",
    "    print(tmp.shape)\n",
    "    wands_year_census_df.append(tmp)\n",
    "wands_year_census_df = pd.concat(wands_year_census_df).reset_index()\n",
    "\n",
    "## Added code to cleanup dataframe\n",
    "ons_cols = ['CompanyNumber', 'CompanyName', 'CompanyStatus', 'PostCode']\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {col:f'ons_{col.lower()}' for col in ons_cols})\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'PostCodeLatitude' : 'lat',\n",
    "                                                             'PostCodeLongitude' : 'lon'})\n",
    "wands_year_census_df['addressline1'] = wands_year_census_df['addressline1'].fillna('')\n",
    "wands_year_census_df.to_csv('Data\\\\Business Cencus CDRC\\\\lam_south_business_census_lsoa.csv', index = False)\n",
    "\n",
    "\n",
    "##clean post code data\n",
    "\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'data_year'])\n",
    "#handle post code length 4 and 3 and 10 and 12\n",
    "wands_year_census_df = wands_year_census_df[wands_year_census_df['postcode'] != 'KENT'].copy()\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if pd.isna(x) else x.strip())\n",
    "\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW16 3SN' if\n",
    "                                                      x == '.' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'N7 9BH' if\n",
    "                                                      x == 'N7' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SE1 0LH' if\n",
    "          (x['postcode'] == 'SE1') and (x['CompanyID'] == 2154406) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SE1 4QF' if\n",
    "          (x['postcode'] == 'SE1') and (x['CompanyID'] == 4352377) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SE1 7NA' if\n",
    "          (x['postcode'] == 'SE1') and (x['CompanyID'] == 2332166) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SE1 5JH' if\n",
    "          (x['postcode'] == 'SE1') and (x['CompanyID'] == 498298) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SW4 6JF' if\n",
    "          (x['postcode'] == 'SW4') and (x['CompanyID'] == 37018) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df.apply(lambda x: 'SW2 1EW' if\n",
    "          (x['postcode'] == 'SW2') and (x['CompanyID'] == 30721) else x['postcode'], axis = 1)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'TN11 0BS' if\n",
    "                                                      x == 'TN11' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE24 0BG' if\n",
    "                                                      x == 'SE24' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE24 0BG' if\n",
    "                                                      x == 'SE24' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'EC2A 4HJ' if\n",
    "                                                      x == 'EC2 A 4HJ' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE15 1RW' if\n",
    "                                                      x == 'SE 15 1RW' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW11 1HA' if\n",
    "                                                      x == 'SW11 1 HA' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE15 1SG' if\n",
    "                                                      x == 'SE15 1 SG' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE28 0LD' if\n",
    "                                                      x == 'SEE28 0LD' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE17 3BA' if\n",
    "                                                      x == 'SE 17 3BA' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'WE17 1DS' if\n",
    "                                                      x == 'WE 17 1DS' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE16 4DG' if\n",
    "                                                      x == 'SE16 4 DG' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE15 6TQ' if\n",
    "                                                      x == 'S E 15 6TQ' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE21 7HP' if\n",
    "                                                      x == 'SE 21 7 HP' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'IG11 8LL' if\n",
    "                                                      x == '07891312648' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'EC4A 1BR' if\n",
    "                                                      x == 'ONE EC4A 1BR' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SE26 6SH' if\n",
    "                                                      x == 'BR3 4RHSE26 6SH' else x)\n",
    "\n",
    "#Handle na in postcode\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].bfill()\n",
    "#Handle missing spaces in post code\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if len(x) != 5\n",
    "                                                     else ' '.join([x[:2], x[2:]]))\n",
    "\n",
    "#Handle 7 char post code with no space\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: ' '.join([x[:4], x[4:]])\n",
    "                                                          if (len(x) == 7) and (' ' not in x) else x)\n",
    "#Handle 6 char post code with no space\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: ' '.join([x[:3], x[3:]])\n",
    "                                                      if (len(x) == 6) and (' ' not in x) else x)\n",
    "#Handle double spaces in post code\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if pd.isna(x) else\n",
    "                                     ' '.join([x.split(' ')[0], x.split(' ')[-1]]))\n",
    "\n",
    "#clean extra chars\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if len(x) != 9\n",
    "                                                     else x[:8])\n",
    "\n",
    "wands_year_census_df = wands_year_census_df.set_index('postcode').join(pc_lsoa_mapping_df.rename(\n",
    "    columns = {'pcds' : 'postcode'}).set_index('postcode')[['oa21cd', 'lsoa21cd', 'msoa21cd',\n",
    "                                                            'ladnm']]).reset_index()\n",
    "wands_year_census_df.to_csv('Data\\\\Business Cencus CDRC\\\\lam_south_business_census_lsoa_pc_cleaned.csv',\n",
    "                            index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199d7bf-e450-4243-9df2-3f5fb2465a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wands_year_census_df = pd.read_csv('Data\\\\Business Cencus CDRC\\\\lam_south_business_census_lsoa_pc_cleaned.csv')\n",
    "wands_year_census_df['addressline1_merge'] = wands_year_census_df['addressline1'].fillna('').apply(\n",
    "    lambda x: re.sub(r'[^\\w\\s]','',x.lower()))\n",
    "print(wands_year_census_df.shape)\n",
    "print(wands_year_census_df[wands_year_census_df['lsoa21cd'].apply(pd.isna)].shape)\n",
    "print(wands_year_census_df[~wands_year_census_df['lsoa21cd'].apply(pd.isna)].shape)\n",
    "print(wands_year_census_df.groupby('CompanyID').count().shape)\n",
    "print(wands_year_census_df.groupby(['CompanyID', 'postcode']).count().shape)\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'data_year' : 'year'})\n",
    "\n",
    "cols = ['CompanyID', 'companynumber', 'companyname', 'addressline1', 'addressline2', 'ons_postcode',\n",
    "        'oa21', 'lsoa21', 'postcode', 'oa21cd', 'lsoa21cd', 'ladnm', 'year']\n",
    "\n",
    "#map census industry to business rate industry\n",
    "sic_cat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'sic_cat_mapping')\n",
    "sic_scat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'scat_sic_mapping')\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'year'])\n",
    "wands_year_census_df['siccode'] = wands_year_census_df['siccode'].bfill()\n",
    "wands_year_census_df = wands_year_census_df.set_index('siccode').join(sic_cat_map_df.set_index('siccode')[[\n",
    "    'sic_category']]).reset_index()\n",
    "wands_year_census_df = wands_year_census_df.set_index('sic_category').join(sic_scat_map_df.set_index(\n",
    "    'sic_category')).reset_index()\n",
    "wands_year_census_df['sic_category'] = wands_year_census_df['sic_category'].fillna('Unclassified')\n",
    "wands_year_census_df['scat_category'] = wands_year_census_df['scat_category'].fillna('Unclassified')\n",
    "wands_year_census_df['scat_sub_category'] = wands_year_census_df['scat_sub_category'].fillna('Unclassified')\n",
    "\n",
    "#identify moved businesses\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'year'])\n",
    "wands_year_census_df['prev_postcode'] = wands_year_census_df.groupby('CompanyID')['postcode'].shift()\n",
    "wands_year_census_df['moved'] = wands_year_census_df.apply(lambda x:\n",
    "        ((x['prev_postcode'] != x['postcode']) and (not pd.isna(x['prev_postcode']))), axis = 1)\n",
    "\n",
    "# filter on wondsworth only\n",
    "wands_year_census_df = wands_year_census_df[wands_year_census_df['ladnm'].isin(['Wandsworth', 'Lambeth', 'Southwark'])].copy()\n",
    "\n",
    "#add correct lon, lat\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'lon' : 'ons_lon',\n",
    "                                                              'lat' : 'ons_lat'})\n",
    "wands_year_census_df = wands_year_census_df.set_index('postcode').join(pc_lon_lat_map_df.rename(columns = {\n",
    "    'pcd2' : 'postcode'}).set_index('postcode')).reset_index()\n",
    "\n",
    "#add survived column\n",
    "wands_year_census_df['survived'] = wands_year_census_df['dissolutiondate'].apply(lambda x: pd.isna(x))\n",
    "\n",
    "#add missing fields\n",
    "wands_year_census_df['floor_area'] = None\n",
    "wands_year_census_df['rental_valuation'] = None\n",
    "wands_year_census_df['rates_expected'] = None\n",
    "\n",
    "wands_year_census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7793a7-d629-4639-b458-fd2482fc89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['CompanyID', 'companyname', 'addressline1', 'postcode', 'dissolutiondate',\n",
    "              'incorporationdate', 'survived', 'year', 'oa21cd', 'lsoa21cd', 'msoa21cd', 'ladnm', 'long', 'lat',\n",
    "              'addressline1_merge', 'scat_sub_category', 'scat_category', 'prev_postcode', 'moved',\n",
    "              'floor_area', 'rental_valuation', 'rates_expected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd9e27-d2dd-42d0-92f6-cdcfe8eb6708",
   "metadata": {},
   "source": [
    "# Match Business Rates and Business Census Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fca44-0929-4979-812e-777272e2d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get exact matches\n",
    "\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "group_cols = ['postcode', 'addressline1_merge', 'year']\n",
    "exact_match_br_census_df = wands_br_lsoa_df[final_cols].set_index(group_cols\n",
    "           ).join(wands_year_census_df[final_cols].set_index(group_cols\n",
    "           ), lsuffix = '_br', rsuffix = '_census', how = 'inner').reset_index()\n",
    "grouped_cols_df = exact_match_br_census_df[group_cols].drop_duplicates()\n",
    "grouped_cols_df['exist'] = True\n",
    "\n",
    "print(exact_match_br_census_df.shape)\n",
    "print(grouped_cols_df.shape)\n",
    "\n",
    "no_exact_wands_br_lsoa_df = wands_br_lsoa_df.set_index(group_cols).join(grouped_cols_df.set_index(group_cols))\n",
    "print(no_exact_wands_br_lsoa_df[~no_exact_wands_br_lsoa_df['exist'].apply(pd.isna)].shape)\n",
    "no_exact_wands_br_lsoa_df = no_exact_wands_br_lsoa_df[no_exact_wands_br_lsoa_df['exist'].apply(pd.isna)\n",
    "                            ].reset_index().drop(columns = ['exist'])\n",
    "print(no_exact_wands_br_lsoa_df.shape)\n",
    "\n",
    "\n",
    "no_exact_wands_year_census_df = wands_year_census_df.set_index(group_cols).join(\n",
    "                    grouped_cols_df.set_index(group_cols))\n",
    "print(no_exact_wands_year_census_df[~no_exact_wands_year_census_df['exist'].apply(pd.isna)].shape)\n",
    "no_exact_wands_year_census_df = no_exact_wands_year_census_df[no_exact_wands_year_census_df['exist'].apply(pd.isna)\n",
    "                            ].reset_index().drop(columns = ['exist'])\n",
    "print(no_exact_wands_year_census_df.shape)\n",
    "\n",
    "### get matches based on postcode and year\n",
    "\n",
    "sub_group_cols = ['postcode', 'year']\n",
    "print(no_exact_wands_br_lsoa_df.shape)\n",
    "print(no_exact_wands_year_census_df.shape)\n",
    "no_exact_match_br_census_df = no_exact_wands_br_lsoa_df[final_cols].set_index(sub_group_cols\n",
    "           ).join(no_exact_wands_year_census_df[final_cols].set_index(sub_group_cols\n",
    "           ), lsuffix = '_br', rsuffix = '_census', how = 'outer').reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "print(no_exact_match_br_census_df[no_exact_match_br_census_df['CompanyID_br'].apply(pd.isna)].shape)\n",
    "print(no_exact_match_br_census_df[no_exact_match_br_census_df['CompanyID_census'].apply(pd.isna)].shape)\n",
    "\n",
    "### get no matches at all and clean matches based on postcode and year\n",
    "\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df[no_exact_match_br_census_df\n",
    "                            ['CompanyID_br'].apply(pd.isna)].copy()\n",
    "drop_cols = [c for c in no_exact_match_br_census_df_census1.columns if '_br' in c]\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df_census1.drop(columns = drop_cols)\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df_census1.rename(columns = {\n",
    "    c:c.replace('_census', '') for c in no_exact_match_br_census_df_census1.columns})\n",
    "no_exact_match_br_census_df_census1['source'] = 'Census'\n",
    "\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df[no_exact_match_br_census_df\n",
    "                            ['CompanyID_census'].apply(pd.isna)].copy()\n",
    "drop_cols = [c for c in no_exact_match_br_census_df_br1.columns if '_census' in c]\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df_br1.drop(columns = drop_cols)\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df_br1.rename(columns = {\n",
    "    c:c.replace('_br', '') for c in no_exact_match_br_census_df_br1.columns})\n",
    "no_exact_match_br_census_df_br1['source'] = 'BR'\n",
    "\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df[\n",
    "                            (~no_exact_match_br_census_df['CompanyID_br'].apply(pd.isna)) &\n",
    "                            (~no_exact_match_br_census_df['CompanyID_census'].apply(pd.isna))]\n",
    "\n",
    "print(no_exact_match_br_census_df_census1.shape)\n",
    "print(no_exact_match_br_census_df_br1.shape)\n",
    "print(no_exact_match_br_census_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa0d67-a772-4f57-b514-09a7395387b2",
   "metadata": {},
   "source": [
    "# Calculate Similarity Based on Deep Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8c361-3d15-4450-94e7-dd5115ad8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('Lajavaness/bilingual-embedding-small', trust_remote_code=True)\n",
    "\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "pc_test = wands_br_lsoa_df.set_index(['postcode',\n",
    "       'year']).join(wands_year_census_df[\n",
    "        cols + ['addressline1_merge']].set_index(['postcode', 'year']), rsuffix = '_census').reset_index()\n",
    "print(pc_test.shape)\n",
    "print(pc_test[pc_test['CompanyID'].apply(pd.isna)].shape)\n",
    "print(pc_test[~pc_test['CompanyID'].apply(pd.isna)].shape)\n",
    "pc_test['match'] = pc_test.apply(lambda x: x['addressline1_merge'] == x['addressline1_merge_census'], axis = 1)\n",
    "print(pc_test[pc_test['match']].shape)\n",
    "print(pc_test[~pc_test['match']].shape)\n",
    "pc_test['addressline1'] = pc_test['addressline1'].fillna('')\n",
    "pc_test['addressline1_census'] = pc_test['addressline1_census'].fillna('')\n",
    "\n",
    "pc_test_tmp = pc_test[['postcode', 'addressline1',\n",
    "      'addressline1_merge', 'addressline1_census', 'addressline1_merge_census']].drop_duplicates()\n",
    "\n",
    "step = 10000\n",
    "n = int(np.ceil(len(pc_test_tmp) / step))\n",
    "pc_test_sim_df = []\n",
    "print('Total steps is:', n)\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    tmp = pc_test_tmp.iloc[i * step: (i+1) * step].copy()\n",
    "    addressline1_embed = model.encode(tmp['addressline1'].tolist())\n",
    "    addressline1_census_embed = model.encode(tmp['addressline1_census'].tolist())\n",
    "    similarity = model.similarity(addressline1_embed, addressline1_census_embed)\n",
    "    tmp['similarity'] = torch.diagonal(similarity, dim1=-2, dim2=-1)\n",
    "    pc_test_sim_df.append(tmp)\n",
    "    print(tmp.shape)\n",
    "    if i % 10 == 0:\n",
    "        pd.concat(pc_test_sim_df, ignore_index = True).to_pickle(\"lam_south_pc_test_sim_df_dedup.pkl\")\n",
    "pc_test_sim_df = pd.concat(pc_test_sim_df, ignore_index = True)\n",
    "pc_test_sim_df.to_pickle(\"lam_south_pc_test_sim_df_dedup.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd21aa0-1f26-46d5-826f-278cb0691361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_test_sim_df_dedup_final = pd.read_pickle('lam_south_pc_test_sim_df_dedup.pkl')\n",
    "print(pc_test_sim_df_dedup_final.shape)\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "test = no_exact_match_br_census_df.set_index(['postcode', 'addressline1_br', 'addressline1_census']\n",
    "        ).join(pc_test_sim_df_dedup_final.rename(columns = {'addressline1' : 'addressline1_br'}\n",
    "        ).set_index(['postcode', 'addressline1_br', 'addressline1_census'])[['similarity']]).reset_index()\n",
    "test['similarity'] = test['similarity'].fillna(0)\n",
    "print(test.shape)\n",
    "print(test[test['similarity'].apply(pd.isna)].shape)\n",
    "print(test[~test['similarity'].apply(pd.isna)].shape)\n",
    "\n",
    "#calc names similarities\n",
    "company_names_map_df = test[test['similarity'] >= 0.8][['postcode', 'addressline1_br', 'addressline1_census',\n",
    "                   'CompanyID_br', 'CompanyID_census', 'year', 'companyname_br', 'companyname_census',\n",
    "       'similarity']].sort_values(by = 'similarity')[[\n",
    "    'companyname_br', 'companyname_census']].drop_duplicates()\n",
    "print(company_names_map_df.shape)\n",
    "company_names_map_df = pd.concat([company_names_map_df, exact_match_br_census_df[[\n",
    "    'companyname_br', 'companyname_census']].drop_duplicates()])\n",
    "print(company_names_map_df.shape)\n",
    "\n",
    "\n",
    "step = 10000\n",
    "n = int(np.ceil(len(company_names_map_df) / step))\n",
    "comp_names_sim_df = []\n",
    "print('Total steps is:', n)\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    tmp = company_names_map_df.iloc[i * step: (i+1) * step].copy()\n",
    "    companyname_br_embed = model.encode(tmp['companyname_br'].fillna('').tolist())\n",
    "    companyname_census_embed = model.encode(tmp['companyname_census'].fillna('').tolist())\n",
    "    similarity = model.similarity(companyname_br_embed, companyname_census_embed)\n",
    "    tmp['similarity'] = torch.diagonal(similarity, dim1=-2, dim2=-1)\n",
    "    comp_names_sim_df.append(tmp)\n",
    "    print(tmp.shape)\n",
    "    if i % 10 == 0:\n",
    "        pd.concat(comp_names_sim_df, ignore_index = True).to_pickle(\"lam_south_comp_names_sim_df.pkl\")\n",
    "comp_names_sim_df = pd.concat(comp_names_sim_df, ignore_index = True)\n",
    "comp_names_sim_df.to_pickle(\"lam_south_comp_names_sim_df.pkl\")\n",
    "\n",
    "comp_names_sim_df = pd.read_pickle('lam_south_comp_names_sim_df.pkl')\n",
    "comp_names_sim_df['companyname_br'] = comp_names_sim_df['companyname_br'].fillna('')\n",
    "comp_names_sim_df['companyname_census'] = comp_names_sim_df['companyname_census'].fillna('')\n",
    "\n",
    "comp_names_sim_df = comp_names_sim_df.rename(columns = {'similarity' : 'names_similarity'})\n",
    "comp_names_sim_df = comp_names_sim_df.drop_duplicates(subset = ['companyname_br', 'companyname_census'])\n",
    "\n",
    "#merge simlarities back to no_exact_match_br_census_df\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['companyname_br', 'companyname_census']).join(\n",
    "    comp_names_sim_df.set_index(['companyname_br', 'companyname_census'])).reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['companyname_br','year']\n",
    "           ).join(no_exact_match_br_census_df[['companyname_br', 'year', 'names_similarity']].groupby(\n",
    "    ['companyname_br', 'year']).max().rename(columns = {'names_similarity' : 'names_max_similarity'}\n",
    "                                        )).reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "no_exact_match_br_census_df['names_match'] = no_exact_match_br_census_df.apply(lambda x: True\n",
    "       if (x['names_similarity'] == x['names_max_similarity']) and\n",
    "       (x['names_similarity'] >= 0.85) else False, axis = 1)\n",
    "\n",
    "\n",
    "no_exact_match_br_census_df['names_similarity'] = no_exact_match_br_census_df['names_similarity'].fillna(0)\n",
    "no_exact_match_br_census_df['names_max_similarity'] = no_exact_match_br_census_df['names_max_similarity'].fillna(0)\n",
    "no_exact_match_br_census_df['names_match'] = no_exact_match_br_census_df['names_match'].fillna(False)\n",
    "\n",
    "#extract matched abd unmatched businesses\n",
    "br_match_agg = no_exact_match_br_census_df[['postcode', 'year', 'companyname_br', 'CompanyID_br',\n",
    "         'names_match']].groupby(['postcode', 'year', 'companyname_br', 'CompanyID_br']\n",
    "                ).agg(list)['names_match'].apply(any)\n",
    "\n",
    "census_match_agg = no_exact_match_br_census_df[['postcode', 'year', 'companyname_census', 'CompanyID_census',\n",
    "         'names_match']].groupby(['postcode', 'year', 'companyname_census', 'CompanyID_census']\n",
    "                ).agg(list)['names_match'].apply(any)\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['postcode', 'year', 'companyname_br',\n",
    "         'CompanyID_br']).join(br_match_agg, rsuffix = '_br').reset_index().set_index(['postcode', 'year',\n",
    "         'companyname_census', 'CompanyID_census']).join(census_match_agg, rsuffix = '_census').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350c4d5-1805-46fc-919f-20cda304aa42",
   "metadata": {},
   "source": [
    "# Merge Datasets Based on Matched ant Non-Matched Scnearios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c9978-59d1-4b2c-a25a-c43c3aa0bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_exact_match_br_census_df_match = no_exact_match_br_census_df[no_exact_match_br_census_df['names_match']].copy()\n",
    "br_cols = [c for c in no_exact_match_br_census_df_match.columns if ('_br' in c) and (c != 'comb_address_no_br')] + ['CompanyID_census', 'companyname_census', 'postcode', 'year']\n",
    "no_exact_match_br_census_df_match = no_exact_match_br_census_df_match[br_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_match.columns = [c.replace('_br','').replace('_census','_alt')\n",
    "                                         for c in no_exact_match_br_census_df_match.columns]\n",
    "no_exact_match_br_census_df_match['source'] = 'Both'\n",
    "\n",
    "no_exact_match_br_census_df_br2 = no_exact_match_br_census_df[\n",
    "                        no_exact_match_br_census_df['names_match_br'] == False]\n",
    "br_cols = [c for c in no_exact_match_br_census_df_br2.columns if ('_br' in c and c != 'comb_address_no_br')] + ['postcode', 'year']\n",
    "no_exact_match_br_census_df_br2 = no_exact_match_br_census_df_br2[br_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_br2.columns = [c.replace('_br','') for c in no_exact_match_br_census_df_br2.columns]\n",
    "no_exact_match_br_census_df_br2['source'] = 'BR'\n",
    "\n",
    "no_exact_match_br_census_df_census2 = no_exact_match_br_census_df[no_exact_match_br_census_df['names_match_census'] == False]\n",
    "census_cols = [c for c in no_exact_match_br_census_df_census2.columns if ('_census' in c and c !=\n",
    "                                         'comb_address_no_census')] + ['postcode', 'year']\n",
    "no_exact_match_br_census_df_census2 = no_exact_match_br_census_df_census2[census_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_census2.columns = [c.replace('_census','') for c in\n",
    "                                              no_exact_match_br_census_df_census2.columns]\n",
    "no_exact_match_br_census_df_census2['source'] = 'Census'\n",
    "\n",
    "print(no_exact_match_br_census_df_match.shape)\n",
    "print(no_exact_match_br_census_df_br2.shape)\n",
    "print(no_exact_match_br_census_df_census2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab128c16-0aad-409c-87d6-931e99020308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact_match_br_census_df.head()\n",
    "print(exact_match_br_census_df.shape)\n",
    "exact_match_br_census_df = exact_match_br_census_df.set_index(['companyname_br', 'companyname_census']).join(\n",
    "    comp_names_sim_df.set_index(['companyname_br', 'companyname_census'])).reset_index()\n",
    "print(exact_match_br_census_df.shape)\n",
    "print(exact_match_br_census_df[exact_match_br_census_df['names_similarity'].apply(pd.isna)].shape)\n",
    "print(exact_match_br_census_df[~exact_match_br_census_df['names_similarity'].apply(pd.isna)].shape)\n",
    "\n",
    "exact_match_br_census_df = exact_match_br_census_df.set_index(['companyname_br','year']\n",
    "           ).join(exact_match_br_census_df[['companyname_br', 'year', 'names_similarity']].groupby(\n",
    "    ['companyname_br', 'year']).max().rename(columns = {'names_similarity' : 'names_max_similarity'}\n",
    "                                        )).reset_index()\n",
    "print(exact_match_br_census_df.shape)\n",
    "exact_match_br_census_df['names_match'] = exact_match_br_census_df.apply(lambda x: True\n",
    "       if (x['names_similarity'] == x['names_max_similarity']) and\n",
    "       (x['names_similarity'] >= 0.85) else False, axis = 1)\n",
    "\n",
    "br_cols = [c for c in exact_match_br_census_df.columns if ('_br' in c) and (c != 'comb_address_no_br')\n",
    "          ] + ['CompanyID_census', 'companyname_census', 'postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df1 = exact_match_br_census_df[exact_match_br_census_df['names_match']].copy()\n",
    "exact_match_br_census_df1 = exact_match_br_census_df1[br_cols].drop_duplicates()\n",
    "exact_match_br_census_df1.columns = [c.replace('_br','').replace('_census','_alt') for c in\n",
    "                                     exact_match_br_census_df1.columns]\n",
    "exact_match_br_census_df1['source'] = 'Both'\n",
    "print(exact_match_br_census_df1.shape)\n",
    "\n",
    "br_cols = [c for c in exact_match_br_census_df.columns if ('_br' in c and c != 'comb_address_no_br')\n",
    "          ] + ['postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df2 = exact_match_br_census_df[\n",
    "                        exact_match_br_census_df['names_match'] == False]\n",
    "exact_match_br_census_df2 = exact_match_br_census_df2[br_cols].drop_duplicates()\n",
    "exact_match_br_census_df2.columns = [c.replace('_br','') for c in exact_match_br_census_df2.columns]\n",
    "exact_match_br_census_df2['source'] = 'BR'\n",
    "print(exact_match_br_census_df2.shape)\n",
    "\n",
    "census_cols = [c for c in exact_match_br_census_df.columns if ('_census' in c and c != 'comb_address_no_census')\n",
    "          ] + ['postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df3 = exact_match_br_census_df[\n",
    "                        exact_match_br_census_df['names_match'] == False]\n",
    "exact_match_br_census_df3 = exact_match_br_census_df3[census_cols].drop_duplicates()\n",
    "exact_match_br_census_df3.columns = [c.replace('_census','') for c in exact_match_br_census_df3.columns]\n",
    "exact_match_br_census_df3['source'] = 'Census'\n",
    "print(exact_match_br_census_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a2309-1517-48dd-979a-170850e1ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = final_cols + ['source']\n",
    "final_br_census_df = pd.concat([no_exact_match_br_census_df_census1[final_cols],\n",
    "                           no_exact_match_br_census_df_br1[final_cols],\n",
    "                           no_exact_match_br_census_df_match[final_cols  + ['CompanyID_alt', 'companyname_alt']],\n",
    "                           no_exact_match_br_census_df_br2[final_cols],\n",
    "                           no_exact_match_br_census_df_census2[final_cols],\n",
    "                           exact_match_br_census_df1[final_cols + ['CompanyID_alt', 'companyname_alt']],\n",
    "                           exact_match_br_census_df2[final_cols],\n",
    "                           exact_match_br_census_df3[final_cols]], ignore_index = True)\n",
    "print(final_br_census_df.shape)\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "print(no_exact_match_br_census_df_match.shape)\n",
    "print(exact_match_br_census_df1.shape)\n",
    "t = final_br_census_df.groupby(['year', 'CompanyID']).count()[['postcode']].sort_values(by = 'postcode').reset_index()\n",
    "t = t[t['postcode'] > 1].copy().drop(columns = 'postcode')\n",
    "print(t.shape)\n",
    "t['duplicate'] = 'True'\n",
    "tmp = final_br_census_df.set_index(['year', 'CompanyID']).join(t.set_index(['year', 'CompanyID'])\n",
    "                                                              ).reset_index()\n",
    "print(tmp[(tmp['duplicate'].apply(pd.isna))].shape)\n",
    "print(tmp[(~tmp['duplicate'].apply(pd.isna))].shape)\n",
    "print(tmp[(~tmp['duplicate'].apply(pd.isna)) & (tmp['source'] == 'Both')].shape)\n",
    "tmp1 = tmp[tmp['duplicate'].apply(pd.isna)].copy().drop(columns = 'duplicate')\n",
    "tmp2 = tmp[(~tmp['duplicate'].apply(pd.isna)) & (tmp['source'] == 'Both')].copy().drop(columns = 'duplicate')\n",
    "final_br_census_df = pd.concat([tmp1, tmp2], ignore_index = True).sort_values(by = ['CompanyID', 'year'])\n",
    "print(final_br_census_df.shape)\n",
    "final_br_census_df.to_pickle(\"lam_south_final_br_census_df_v5.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
