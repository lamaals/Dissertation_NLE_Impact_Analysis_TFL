{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ba8657-0360-477b-ac3d-cb3adbb1f199",
   "metadata": {},
   "source": [
    "### Dissertation Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f0fd0-f8d0-4f40-b861-d9077a850d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from collections import Counter\n",
    "from geopy.distance import geodesic\n",
    "from dateutil.parser import parse\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "def get_moved(x, col = 'bus_prox_class'):\n",
    "    if not x['moved']:\n",
    "        return False, False, False\n",
    "    else:\n",
    "        if pd.isna(x[f'prev_{col}']):\n",
    "            return True, False, False\n",
    "        else:\n",
    "            if x[f'prev_{col}'] < x[col]:\n",
    "                if col == 'prox_class':\n",
    "                    return False, True, False\n",
    "                else:\n",
    "                    return True, False, False\n",
    "            elif x[f'prev_{col}'] > x[col]:\n",
    "                if col == 'prox_class':\n",
    "                    return True, False, False\n",
    "                else:\n",
    "                    return False, True, False\n",
    "            else:\n",
    "                return False, False, True\n",
    "\n",
    "def get_moved_within(x, col = 'oa21cd'):\n",
    "    if not x['moved']:\n",
    "        return False\n",
    "    else:\n",
    "        if pd.isna(x[f'prev_{col}']):\n",
    "            return False\n",
    "        else:\n",
    "            if x[f'prev_{col}'] == x[col]:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "def get_status_date(x, df):\n",
    "    if pd.isna(x['status_date']):\n",
    "        tmp = df[(df['rates_code'] == x['rates_code']) & (df['location_code'] == x['location_code'])].copy()\n",
    "        if len(tmp):\n",
    "            return tmp['status_date'].iloc[0]\n",
    "        else:\n",
    "            if pd.isna(x['occupation_date']):\n",
    "                return x['from_date']\n",
    "            else:\n",
    "                return x['occupation_date']\n",
    "    else:\n",
    "        return x['status_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c362de-55f2-47ef-8bc5-a148e0c727c2",
   "metadata": {},
   "source": [
    "# Preprocess Business Rate Data and Clean wrong Postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0722ae9-ef32-4dbd-86e3-72cc4841ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data files \n",
    "# use glob to get all the CSV files in the folder\n",
    "path = 'Data\\\\business rate data\\\\Wandsworth\\\\'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# loop over the list of CSV files\n",
    "wands_br_df= []\n",
    "for f in csv_files:\n",
    "    \n",
    "    df = pd.read_csv(f)\n",
    "    df['quarter']= f.split(\"\\\\\")[-1][:7]\n",
    "    wands_br_df.append(df)\n",
    "# Dataframe concatenation\n",
    "wands_br_df= pd.concat(wands_br_df, ignore_index=True)\n",
    "\n",
    "\n",
    "wands_br_2024_df = pd.read_csv(\"Data\\\\business rate data\\\\alswliman\\\\period-2021-to-2024-E09000032-wandsworth.csv\")\n",
    "wands_br_2024_df = wands_br_2024_df.rename(columns = {'filter_period' : 'period', 'billing_authority_name' : 'rates_authority',\n",
    "                     'geocode' : 'rates_authority_id', 'uarn' : 'location_code', 'billing_reference' : 'rates_code',\n",
    "                     'account_name' : 'name', 'account_start_date' : 'status_date', 'searchable_address' : 'address_street',\n",
    "                     'postcode_id' : 'pc__pcs', 'category_id' : 'scat_code', 'primary_description' : 'use_category',\n",
    "                     'category_subgroup' : 'sub_category', 'category_group' : 'category', 'rates_payable' : 'rates_expected',\n",
    "                     'rateable_value' : 'rental_valuation', 'total_floor_area' : 'floor_area'})\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = ['geometry', 'occupation_state', 'unit_of_measure', 'series', 'epoch'])\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['period'] = wands_br_2024_df['period'].apply(lambda x: '-'.join([x.split('-')[0], x.split('-')[1]]))\n",
    "wands_br_2024_df['quarter'] = wands_br_2024_df['period']\n",
    "wands_br_2024_df = wands_br_2024_df[wands_br_2024_df['period'].apply(lambda x: int(x.split('-')[1])) == 12].copy()\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.groupby(['rates_code', 'location_code'])['status_date'].ffill()\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.groupby(['rates_code', 'location_code'])['status_date'].bfill()\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_2024_df[wands_br_2024_df['status_date'].apply(pd.isna)].shape)\n",
    "#wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: get_status_date(x, wands_br_df), axis = 1)\n",
    "\n",
    "wands_br_rates_code_df = wands_br_df[['rates_code', 'location_code', 'name', 'status_date'\n",
    "                                     ]].rename(columns = {'status_date' : 'old_status_date'})\n",
    "wands_br_rates_code_df['old_status_date'] = wands_br_rates_code_df['old_status_date'].apply(\n",
    "    lambda x: str(parse(x)).split(' ')[0] if isinstance(x, str) else str(x).split(' ')[0])\n",
    "wands_br_rates_code_df = wands_br_rates_code_df.drop_duplicates()\n",
    "wands_br_rates_code_df = wands_br_rates_code_df.groupby(['rates_code', 'location_code', 'name']).min().reset_index()\n",
    "print(wands_br_rates_code_df.shape)\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df = wands_br_2024_df.set_index(['rates_code', 'location_code', 'name']).join(\n",
    "    wands_br_rates_code_df.set_index(['rates_code', 'location_code', 'name'])).reset_index()\n",
    "print(wands_br_2024_df.shape)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['old_status_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = ['old_status_date'])\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['occupation_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "wands_br_2024_df['status_date'] = wands_br_2024_df.apply(lambda x: x['from_date'] if pd.isna(x['status_date'])\n",
    "                                                         else x['status_date'], axis = 1)\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_2024_df[wands_br_2024_df['status_date'].apply(pd.isna)].shape)\n",
    "\n",
    "drop_cols = list(set(wands_br_2024_df.columns) - set(wands_br_df.columns))\n",
    "print(drop_cols)\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = drop_cols)\n",
    "ext_cols = list(set(wands_br_df.columns) - set(wands_br_2024_df.columns))\n",
    "print(ext_cols)\n",
    "for col in ext_cols:\n",
    "    wands_br_2024_df[col] = np.nan\n",
    "\n",
    "drop_cols = list(set(wands_br_2024_df.columns) - set(wands_br_df.columns))\n",
    "print(drop_cols)\n",
    "wands_br_2024_df = wands_br_2024_df.drop(columns = drop_cols)\n",
    "ext_cols = list(set(wands_br_df.columns) - set(wands_br_2024_df.columns))\n",
    "print(ext_cols)\n",
    "for col in ext_cols:\n",
    "    wands_br_2024_df[col] = np.nan\n",
    "wands_br_df = pd.concat([wands_br_df, wands_br_2024_df[wands_br_df.columns]], ignore_index = True)\n",
    "print(wands_br_df.shape)\n",
    "print(wands_br_2024_df.shape)\n",
    "print(wands_br_df.shape)\n",
    "wands_br_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70ca4e-6c48-46c0-bd8c-9667341135bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lon_lat_map_df = pd.read_csv(\"Data/ONSPD_MAY_2025_UK_SW.csv\")\n",
    "pc_lon_lat_map_df = pc_lon_lat_map_df[['pcd2', 'lat', 'long']]\n",
    "pc_lon_lat_map_df['pcd2'] = pc_lon_lat_map_df['pcd2'].apply(lambda x: ' '.join([x.split(' ')[0],\n",
    "                                                            x.split(' ')[-1]]))\n",
    "\n",
    "pc_lsoa_mapping_df = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\PCD_OA21_LSOA21.csv\", encoding = \"ISO-8859-1\")\n",
    "pc_lsoa_mapping_df = pc_lsoa_mapping_df[pc_lsoa_mapping_df['ladnm'] == 'Wandsworth'].copy()\n",
    "pc_lsoa_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb13d73-c833-4d98-afaf-1eec898121f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_pc_mapping = {'SW12 0BP' : 'SW12 0BT', 'SW12 0AB' : 'SW12 0BT', 'SW12 0HY' : 'SW12 0PJ',\n",
    "'SW12 0NA' : 'SW12 0BS', 'SW12 0PH' : 'SW12 0PJ', 'SW12 0LT' : 'SW12 0BT',\n",
    "'SW12 0PQ' : 'SW12 0PJ', 'SW12 0PS' : 'SW12 0PL', 'SW17 0AY' : 'SW17 0AS',\n",
    "'SW17 0BH' : 'SW17 0BQ', 'SW4 0PT' : 'SW4 0QE', 'SW8 3LG' : 'SW8 3DJ'}\n",
    "wands_br_df['closest_pc'] = wands_br_df['pc__pcs'].apply(lambda x: x if x not in closest_pc_mapping\n",
    "                                                        else closest_pc_mapping[x])\n",
    "wands_br_lsoa_df = wands_br_df.set_index('closest_pc').join(pc_lsoa_mapping_df.rename(\n",
    "    columns = {'pcds' : 'closest_pc'}).set_index('closest_pc')[['oa21cd', 'lsoa21cd', 'msoa21cd']]).reset_index()\n",
    "wands_br_lsoa_df['year'] = wands_br_lsoa_df['quarter'].apply(lambda x: int(x.split('-')[0]))\n",
    "wands_br_lsoa_df['address_no'] = wands_br_lsoa_df['address_no'].fillna('')\n",
    "wands_br_lsoa_df['addressline1'] = wands_br_lsoa_df.apply(lambda x:\n",
    "                                  ' '.join([x['address_no'], x['address_street']]), axis = 1)\n",
    "wands_br_lsoa_df['addressline1_merge'] = wands_br_lsoa_df['addressline1'].fillna('').apply(\n",
    "    lambda x: re.sub(r'[^\\w\\s]','',x.lower()))\n",
    "\n",
    "#fix missing names\n",
    "br_cols = ['closest_pc', 'pc__pcs', 'rates_code', 'location_code', 'address_no',\n",
    "           'address_street', 'use_category', 'sub_category', 'category', 'rental_valuation',\n",
    "           'valuation_date', 'period', 'rates_expected', 'name', 'status', 'status_date', 'quarter']\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.sort_values(by = ['rates_code', 'period'])\n",
    "wands_br_lsoa_df['name'] = wands_br_lsoa_df['name'].bfill()\n",
    "\n",
    "#add min and mex periods\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('rates_code').join(wands_br_lsoa_df[['rates_code', 'period'\n",
    "        ]].groupby('rates_code').min().rename(columns = {'period' : 'min_period'})).reset_index()\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('rates_code').join(wands_br_lsoa_df[['rates_code', 'period'\n",
    "        ]].groupby('rates_code').max().rename(columns = {'period' : 'max_period'})).reset_index()\n",
    "\n",
    "#reduce business rate data to yearly\n",
    "wands_br_lsoa_df['quarter'] = wands_br_lsoa_df['quarter'].apply(lambda x: int(x.split('-')[1]))\n",
    "quarter_wands_br_lsoa_df = wands_br_lsoa_df.copy()\n",
    "wands_br_lsoa_df = wands_br_lsoa_df[(wands_br_lsoa_df['quarter'] == 12)].copy()\n",
    "\n",
    "\n",
    "#map post code to lon, lat\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.set_index('closest_pc').join(pc_lon_lat_map_df.rename(columns = {\n",
    "    'pcd2' : 'closest_pc'}).set_index('closest_pc')).reset_index()\n",
    "\n",
    "# add dissolutiondate and incorporationdate\n",
    "wands_br_lsoa_df['dissolutiondate'] = wands_br_lsoa_df['max_period'].apply(lambda x: np.nan\n",
    "                                                   if x == '2024-12' else x + '-01')\n",
    "wands_br_lsoa_df['incorporationdate'] = wands_br_lsoa_df['status_date']\n",
    "\n",
    "#identify moved businesses\n",
    "wands_br_lsoa_df['postcode'] = wands_br_lsoa_df['closest_pc']\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.sort_values(by = ['rates_code', 'year'])\n",
    "wands_br_lsoa_df['prev_postcode'] = wands_br_lsoa_df.groupby('rates_code')['postcode'].shift()\n",
    "wands_br_lsoa_df['moved'] = wands_br_lsoa_df.apply(lambda x:\n",
    "        ((x['prev_postcode'] != x['postcode']) and (not pd.isna(x['prev_postcode']))), axis = 1)\n",
    "\n",
    "#add company name and company id\n",
    "wands_br_lsoa_df['companyname'] = wands_br_lsoa_df['name']\n",
    "wands_br_lsoa_df['rates_code'] = wands_br_lsoa_df['rates_code'].apply(lambda x: str(int(float(x))) if 'E+' in str(x) else x)\n",
    "wands_br_lsoa_df['CompanyID'] = wands_br_lsoa_df['rates_code']\n",
    "\n",
    "#########################\n",
    "print(wands_br_lsoa_df.shape)\n",
    "t = wands_br_lsoa_df.fillna('').groupby(['year', 'CompanyID']).count().sort_values(by = 'companyname').reset_index()\n",
    "ids = t[t['companyname'] > 1]['CompanyID'].unique()\n",
    "wands_br_lsoa_df_tmp = wands_br_lsoa_df[wands_br_lsoa_df['CompanyID'].isin(ids)].copy()\n",
    "wands_br_lsoa_df_tmp['CompanyID'] = wands_br_lsoa_df_tmp.apply(lambda x: '-'.join([x['CompanyID'],\n",
    "                                                                       str(x['location_code']), x['name']]), axis = 1)\n",
    "wands_br_lsoa_df = pd.concat([wands_br_lsoa_df_tmp, wands_br_lsoa_df[~wands_br_lsoa_df['CompanyID'].isin(ids)]])\n",
    "print(wands_br_lsoa_df.shape)\n",
    "#########################\n",
    "\n",
    "#add scat categories and survived\n",
    "wands_br_lsoa_df['category'] = wands_br_lsoa_df.apply(lambda x: x['sub_category']\n",
    "                                  if pd.isna(x['category']) else x['category'], axis = 1)\n",
    "wands_br_lsoa_df['scat_sub_category'] = wands_br_lsoa_df['sub_category']\n",
    "wands_br_lsoa_df['scat_category'] = wands_br_lsoa_df['category']\n",
    "wands_br_lsoa_df['survived'] = wands_br_lsoa_df['dissolutiondate'].apply(lambda x: pd.isna(x))\n",
    "\n",
    "wands_br_lsoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e656b-7bbd-4cb3-b81f-c045effaee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = wands_br_lsoa_df.groupby(['CompanyID', 'companyname', 'year']).count()[['postcode']\n",
    "                    ].reset_index().groupby(['companyname', 'year']).count().reset_index()\n",
    "print(s[s['CompanyID'] > 1].shape)\n",
    "print(s[s['CompanyID'] == 1].shape)\n",
    "companies = s['companyname'].unique()\n",
    "non_uniq_companies = s[s['CompanyID'] != 1]['companyname'].unique()\n",
    "uniq_companies = list(set(companies) - set(non_uniq_companies))\n",
    "print(len(uniq_companies))\n",
    "print(len(non_uniq_companies))\n",
    "print(len(companies))\n",
    "print(wands_br_lsoa_df.shape)\n",
    "wands_br_lsoa_df = wands_br_lsoa_df[wands_br_lsoa_df['companyname'].isin(uniq_companies)]\n",
    "print(wands_br_lsoa_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37eabc-b47e-4b4e-b4c2-e63aee08752f",
   "metadata": {},
   "source": [
    "### Processing Business Census Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b044e5-5854-45c1-b331-f9574b8a9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Wandsworth ONS mapping data\n",
    "cols = ['CompanyID', 'CompanyNumber', 'CompanyName', 'CompanyStatus', 'PostCode',\n",
    "       'oa11', 'lsoa11', 'msoa11', 'oa21', 'lsoa21', 'msoa21', 'PostCodeLatitude', 'PostCodeLongitude']\n",
    "ons_df = pd.read_csv(\"Data\\Business Cencus CDRC\\entities\\\\ONSGeography.csv.zip\",\n",
    "#                     compression='zip', nrows=100, usecols=cols)\n",
    "                      compression='zip', usecols=cols)\n",
    "wands_ons_df = ons_df[ons_df['lsoa21'].isin(pc_lsoa_mapping_df['lsoa21cd'].unique())].copy()\n",
    "wands_ons_df.to_csv('Data\\Business Cencus CDRC\\entities\\Wandsowrth_ONSGeography.csv', index = False)\n",
    "\n",
    "## Combine Business Census data with Wandsworth ONS data\n",
    "\n",
    "wands_year_census_df = []\n",
    "for i in range(13):\n",
    "    year = 2012 + i\n",
    "    census_df = pd.read_csv(f\"Data\\\\Business Cencus CDRC\\\\business_census{year}.csv.zip\", compression='zip')\n",
    "    census_df['data_year'] = year\n",
    "    tmp = census_df.rename(columns = {'id' : 'CompanyID'}).set_index('CompanyID').join(\n",
    "        wands_ons_df.set_index('CompanyID'), how = 'inner')\n",
    "    print(tmp.shape)\n",
    "    wands_year_census_df.append(tmp)\n",
    "wands_year_census_df = pd.concat(wands_year_census_df).reset_index()\n",
    "\n",
    "## Added code to cleanup dataframe\n",
    "ons_cols = ['CompanyNumber', 'CompanyName', 'CompanyStatus', 'PostCode']\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {col:f'ons_{col.lower()}' for col in ons_cols})\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'PostCodeLatitude' : 'lat',\n",
    "                                                             'PostCodeLongitude' : 'lon'})\n",
    "wands_year_census_df['addressline1'] = wands_year_census_df['addressline1'].fillna('')\n",
    "wands_year_census_df.to_csv('Data\\\\Business Cencus CDRC\\\\business_census_lsoa.csv', index = False)\n",
    "\n",
    "##clean post code data\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'data_year'])\n",
    "#handle post code length 4 and 3 and 10 and 12\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if pd.isna(x) else x.strip())\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'CR4 2LU' if\n",
    "                                                      x == 'CR 4 2 LU' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW17 0JT' if\n",
    "                                                      x == '3800-003' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW18 1FX' if\n",
    "                                                      x == 'SW18 1FX, UK' else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW18 1EA' if x == 'SW 18 1 EA'\n",
    "                                                                          else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'W11 2NH' if x == 'W11'\n",
    "                                                                          else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW18 3LG' if x == 'SW18'\n",
    "                                                                          else x)\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: 'SW17 8TB' if x == 'SW17'\n",
    "                                                                          else x)\n",
    "#Handle na in postcode\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].bfill()\n",
    "#Handle missing spaces in post code\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if len(x) != 5\n",
    "                                                     else ' '.join([x[:2], x[2:]]))\n",
    "#Handle 7 char post code with no space\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: ' '.join([x[:4], x[4:]])\n",
    "                                                          if (len(x) == 7) and (' ' not in x) else x)\n",
    "#Handle 6 char post code with no space\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: ' '.join([x[:3], x[3:]])\n",
    "                                                      if (len(x) == 6) and (' ' not in x) else x)\n",
    "#Handle double spaces in post code\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if pd.isna(x) else\n",
    "                                     ' '.join([x.split(' ')[0], x.split(' ')[-1]]))\n",
    "#clean extra chars\n",
    "wands_year_census_df['postcode'] = wands_year_census_df['postcode'].apply(lambda x: x if len(x) != 9\n",
    "                                                     else x[:8])\n",
    "wands_year_census_df = wands_year_census_df.set_index('postcode').join(pc_lsoa_mapping_df.rename(\n",
    "    columns = {'pcds' : 'postcode'}).set_index('postcode')[['oa21cd', 'lsoa21cd', 'msoa21cd',\n",
    "                                                            'ladnm']]).reset_index()\n",
    "wands_year_census_df.to_csv('Data\\\\Business Cencus CDRC\\\\business_census_lsoa_pc_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199d7bf-e450-4243-9df2-3f5fb2465a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wands_ons_df = pd.read_csv('Data\\Business Cencus CDRC\\entities\\Wandsowrth_ONSGeography.csv')\n",
    "wands_year_census_df = pd.read_csv('Data\\\\Business Cencus CDRC\\\\business_census_lsoa_pc_cleaned.csv')\n",
    "wands_year_census_df['addressline1_merge'] = wands_year_census_df['addressline1'].fillna('').apply(\n",
    "    lambda x: re.sub(r'[^\\w\\s]','',x.lower()))\n",
    "print(wands_year_census_df.shape)\n",
    "print(wands_year_census_df[wands_year_census_df['lsoa21cd'].apply(pd.isna)].shape)\n",
    "print(wands_year_census_df[~wands_year_census_df['lsoa21cd'].apply(pd.isna)].shape)\n",
    "print(wands_year_census_df.groupby('CompanyID').count().shape)\n",
    "print(wands_year_census_df.groupby(['CompanyID', 'postcode']).count().shape)\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'data_year' : 'year'})\n",
    "\n",
    "cols = ['CompanyID', 'companynumber', 'companyname', 'addressline1', 'addressline2', 'ons_postcode',\n",
    "        'oa21', 'lsoa21', 'postcode', 'oa21cd', 'lsoa21cd', 'ladnm', 'year']\n",
    "\n",
    "#map census industry to business rate industry\n",
    "sic_cat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'sic_cat_mapping')\n",
    "sic_scat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'scat_sic_mapping')\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'year'])\n",
    "wands_year_census_df['siccode'] = wands_year_census_df['siccode'].bfill()\n",
    "wands_year_census_df = wands_year_census_df.set_index('siccode').join(sic_cat_map_df.set_index('siccode')[[\n",
    "    'sic_category']]).reset_index()\n",
    "wands_year_census_df = wands_year_census_df.set_index('sic_category').join(sic_scat_map_df.set_index(\n",
    "    'sic_category')).reset_index()\n",
    "wands_year_census_df['sic_category'] = wands_year_census_df['sic_category'].fillna('Unclassified')\n",
    "wands_year_census_df['scat_category'] = wands_year_census_df['scat_category'].fillna('Unclassified')\n",
    "wands_year_census_df['scat_sub_category'] = wands_year_census_df['scat_sub_category'].fillna('Unclassified')\n",
    "\n",
    "#identify moved businesses\n",
    "wands_year_census_df = wands_year_census_df.sort_values(by = ['CompanyID', 'year'])\n",
    "wands_year_census_df['prev_postcode'] = wands_year_census_df.groupby('CompanyID')['postcode'].shift()\n",
    "wands_year_census_df['moved'] = wands_year_census_df.apply(lambda x:\n",
    "        ((x['prev_postcode'] != x['postcode']) and (not pd.isna(x['prev_postcode']))), axis = 1)\n",
    "\n",
    "# filter on wondsworth only\n",
    "wands_year_census_df = wands_year_census_df[wands_year_census_df['ladnm'].isin(['Wandsworth', 'Lambeth'])].copy()\n",
    "\n",
    "#add correct lon, lat\n",
    "wands_year_census_df = wands_year_census_df.rename(columns = {'lon' : 'ons_lon',\n",
    "                                                              'lat' : 'ons_lat'})\n",
    "wands_year_census_df = wands_year_census_df.set_index('postcode').join(pc_lon_lat_map_df.rename(columns = {\n",
    "    'pcd2' : 'postcode'}).set_index('postcode')).reset_index()\n",
    "\n",
    "#add survived column\n",
    "wands_year_census_df['survived'] = wands_year_census_df['dissolutiondate'].apply(lambda x: pd.isna(x))\n",
    "\n",
    "#add missing fields\n",
    "wands_year_census_df['floor_area'] = None\n",
    "wands_year_census_df['rental_valuation'] = None\n",
    "wands_year_census_df['rates_expected'] = None\n",
    "\n",
    "wands_year_census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e88c2b-88f1-4b57-86f9-3748b9de0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wands_year_census_df[wands_year_census_df['CompanyID'].apply(lambda x: isinstance(x, str))].shape)\n",
    "print(wands_year_census_df[~wands_year_census_df['CompanyID'].apply(lambda x: isinstance(x, str))].shape)\n",
    "print(wands_year_census_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7793a7-d629-4639-b458-fd2482fc89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['CompanyID', 'companyname', 'addressline1', 'postcode', 'dissolutiondate',\n",
    "              'incorporationdate', 'survived', 'year', 'oa21cd', 'lsoa21cd', 'msoa21cd', 'ladnm', 'long', 'lat',\n",
    "              'addressline1_merge', 'scat_sub_category', 'scat_category', 'prev_postcode', 'moved',\n",
    "              'floor_area', 'rental_valuation', 'rates_expected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f9dfd-afbf-4b8e-a755-f0b3749f16d0",
   "metadata": {},
   "source": [
    "# Match Business Rates and Business Census Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fca44-0929-4979-812e-777272e2d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get exact matches\n",
    "\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "wands_br_lsoa_df = wands_br_lsoa_df.rename(columns = {'rates_authority' : 'ladnm'})\n",
    "group_cols = ['postcode', 'addressline1_merge', 'year']\n",
    "exact_match_br_census_df = wands_br_lsoa_df[final_cols].set_index(group_cols\n",
    "           ).join(wands_year_census_df[final_cols].set_index(group_cols\n",
    "           ), lsuffix = '_br', rsuffix = '_census', how = 'inner').reset_index()\n",
    "grouped_cols_df = exact_match_br_census_df[group_cols].drop_duplicates()\n",
    "grouped_cols_df['exist'] = True\n",
    "\n",
    "print(exact_match_br_census_df.shape)\n",
    "print(grouped_cols_df.shape)\n",
    "\n",
    "no_exact_wands_br_lsoa_df = wands_br_lsoa_df.set_index(group_cols).join(grouped_cols_df.set_index(group_cols))\n",
    "print(no_exact_wands_br_lsoa_df[~no_exact_wands_br_lsoa_df['exist'].apply(pd.isna)].shape)\n",
    "no_exact_wands_br_lsoa_df = no_exact_wands_br_lsoa_df[no_exact_wands_br_lsoa_df['exist'].apply(pd.isna)\n",
    "                            ].reset_index().drop(columns = ['exist'])\n",
    "print(no_exact_wands_br_lsoa_df.shape)\n",
    "\n",
    "\n",
    "no_exact_wands_year_census_df = wands_year_census_df.set_index(group_cols).join(\n",
    "                    grouped_cols_df.set_index(group_cols))\n",
    "print(no_exact_wands_year_census_df[~no_exact_wands_year_census_df['exist'].apply(pd.isna)].shape)\n",
    "no_exact_wands_year_census_df = no_exact_wands_year_census_df[no_exact_wands_year_census_df['exist'].apply(pd.isna)\n",
    "                            ].reset_index().drop(columns = ['exist'])\n",
    "print(no_exact_wands_year_census_df.shape)\n",
    "\n",
    "### get matches based on postcode and year\n",
    "\n",
    "sub_group_cols = ['postcode', 'year']\n",
    "print(no_exact_wands_br_lsoa_df.shape)\n",
    "print(no_exact_wands_year_census_df.shape)\n",
    "no_exact_match_br_census_df = no_exact_wands_br_lsoa_df[final_cols].set_index(sub_group_cols\n",
    "           ).join(no_exact_wands_year_census_df[final_cols].set_index(sub_group_cols\n",
    "           ), lsuffix = '_br', rsuffix = '_census', how = 'outer').reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "print(no_exact_match_br_census_df[no_exact_match_br_census_df['CompanyID_br'].apply(pd.isna)].shape)\n",
    "print(no_exact_match_br_census_df[no_exact_match_br_census_df['CompanyID_census'].apply(pd.isna)].shape)\n",
    "\n",
    "### get no matches at all and clean matches based on postcode and year\n",
    "\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df[no_exact_match_br_census_df\n",
    "                            ['CompanyID_br'].apply(pd.isna)].copy()\n",
    "drop_cols = [c for c in no_exact_match_br_census_df_census1.columns if '_br' in c]\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df_census1.drop(columns = drop_cols)\n",
    "no_exact_match_br_census_df_census1 = no_exact_match_br_census_df_census1.rename(columns = {\n",
    "    c:c.replace('_census', '') for c in no_exact_match_br_census_df_census1.columns})\n",
    "no_exact_match_br_census_df_census1['source'] = 'Census'\n",
    "\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df[no_exact_match_br_census_df\n",
    "                            ['CompanyID_census'].apply(pd.isna)].copy()\n",
    "drop_cols = [c for c in no_exact_match_br_census_df_br1.columns if '_census' in c]\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df_br1.drop(columns = drop_cols)\n",
    "no_exact_match_br_census_df_br1 = no_exact_match_br_census_df_br1.rename(columns = {\n",
    "    c:c.replace('_br', '') for c in no_exact_match_br_census_df_br1.columns})\n",
    "no_exact_match_br_census_df_br1['source'] = 'BR'\n",
    "\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df[\n",
    "                            (~no_exact_match_br_census_df['CompanyID_br'].apply(pd.isna)) &\n",
    "                            (~no_exact_match_br_census_df['CompanyID_census'].apply(pd.isna))]\n",
    "\n",
    "print(no_exact_match_br_census_df_census1.shape)\n",
    "print(no_exact_match_br_census_df_br1.shape)\n",
    "print(no_exact_match_br_census_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d32b7-19dd-4b8d-9e43-a35a653b7425",
   "metadata": {},
   "source": [
    "# Calculate Similarity Based on Deep Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1aeb04-ca2b-47f6-ac8a-d81fc12f07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('Lajavaness/bilingual-embedding-small', trust_remote_code=True)\n",
    "\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "print(wands_year_census_df[wands_year_census_df['ladnm'] == 'Wandsworth'].shape)\n",
    "pc_test = wands_br_lsoa_df.rename(columns = {'pc__pcs' : 'postcode', 'year' : 'data_year'}).set_index(['postcode',\n",
    "       'data_year']).join(wands_year_census_df[wands_year_census_df['ladnm'] == 'Wandsworth'][\n",
    "        cols + ['addressline1_merge']].set_index(['postcode', 'data_year']), rsuffix = '_census').reset_index()\n",
    "print(pc_test.shape)\n",
    "print(pc_test[pc_test['CompanyID'].apply(pd.isna)].shape)\n",
    "print(pc_test[~pc_test['CompanyID'].apply(pd.isna)].shape)\n",
    "pc_test['match'] = pc_test.apply(lambda x: x['addressline1_merge'] == x['addressline1_merge_census'], axis = 1)\n",
    "print(pc_test[pc_test['match']].shape)\n",
    "print(pc_test[~pc_test['match']].shape)\n",
    "pc_test['addressline1'] = pc_test['addressline1'].fillna('')\n",
    "pc_test['addressline1_census'] = pc_test['addressline1_census'].fillna('')\n",
    "\n",
    "pc_test_tmp = pc_test.iloc[1810000:][['postcode', 'addressline1',\n",
    "      'addressline1_merge', 'addressline1_census', 'addressline1_merge_census']].drop_duplicates()\n",
    "\n",
    "step = 10000\n",
    "n = int(np.ceil(len(pc_test_tmp) / step))\n",
    "pc_test_sim_df = []\n",
    "print('Total steps is:', n)\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    tmp = pc_test_tmp.iloc[i * step: (i+1) * step].copy()\n",
    "    addressline1_embed = model.encode(tmp['addressline1'].tolist())\n",
    "    addressline1_census_embed = model.encode(tmp['addressline1_census'].tolist())\n",
    "    similarity = model.similarity(addressline1_embed, addressline1_census_embed)\n",
    "    tmp['similarity'] = torch.diagonal(similarity, dim1=-2, dim2=-1)\n",
    "    pc_test_sim_df.append(tmp)\n",
    "    print(tmp.shape)\n",
    "    if i % 10 == 0:\n",
    "        pd.concat(pc_test_sim_df, ignore_index = True).to_pickle(\"pc_test_sim_df_dedup.pkl\")\n",
    "pc_test_sim_df = pd.concat(pc_test_sim_df, ignore_index = True)\n",
    "pc_test_sim_df.to_pickle(\"pc_test_sim_df_dedup.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd21aa0-1f26-46d5-826f-278cb0691361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_test_sim_df_dedup_final = pd.read_pickle('pc_test_sim_df_dedup_final.pkl')\n",
    "print(pc_test_sim_df_dedup_final.shape)\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "test = no_exact_match_br_census_df.set_index(['postcode', 'addressline1_br', 'addressline1_census']\n",
    "        ).join(pc_test_sim_df_dedup_final.rename(columns = {'addressline1' : 'addressline1_br'}\n",
    "        ).set_index(['postcode', 'addressline1_br', 'addressline1_census'])[['similarity']]).reset_index()\n",
    "test['similarity'] = test['similarity'].fillna(0)\n",
    "print(test.shape)\n",
    "print(test[test['similarity'].apply(pd.isna)].shape)\n",
    "print(test[~test['similarity'].apply(pd.isna)].shape)\n",
    "\n",
    "#calc names similarities\n",
    "company_names_map_df = test[test['similarity'] >= 0.8][['postcode', 'addressline1_br', 'addressline1_census',\n",
    "                   'CompanyID_br', 'CompanyID_census', 'year', 'companyname_br', 'companyname_census',\n",
    "       'similarity']].sort_values(by = 'similarity')[[\n",
    "    'companyname_br', 'companyname_census']].drop_duplicates()\n",
    "print(company_names_map_df.shape)\n",
    "company_names_map_df = pd.concat([company_names_map_df, exact_match_br_census_df[[\n",
    "    'companyname_br', 'companyname_census']].drop_duplicates()])\n",
    "print(company_names_map_df.shape)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('Lajavaness/bilingual-embedding-small', trust_remote_code=True)\n",
    "\n",
    "step = 10000\n",
    "n = int(np.ceil(len(company_names_map_df) / step))\n",
    "comp_names_sim_df = []\n",
    "print('Total steps is:', n)\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    tmp = company_names_map_df.iloc[i * step: (i+1) * step].copy()\n",
    "    companyname_br_embed = model.encode(tmp['companyname_br'].fillna('').tolist())\n",
    "    companyname_census_embed = model.encode(tmp['companyname_census'].fillna('').tolist())\n",
    "    similarity = model.similarity(companyname_br_embed, companyname_census_embed)\n",
    "    tmp['similarity'] = torch.diagonal(similarity, dim1=-2, dim2=-1)\n",
    "    comp_names_sim_df.append(tmp)\n",
    "    print(tmp.shape)\n",
    "    if i % 10 == 0:\n",
    "        pd.concat(comp_names_sim_df, ignore_index = True).to_pickle(\"comp_names_sim_df.pkl\")\n",
    "comp_names_sim_df = pd.concat(comp_names_sim_df, ignore_index = True)\n",
    "comp_names_sim_df.to_pickle(\"comp_names_sim_df.pkl\")\n",
    "\n",
    "comp_names_sim_df = pd.read_pickle('comp_names_sim_df.pkl')\n",
    "comp_names_sim_df['companyname_br'] = comp_names_sim_df['companyname_br'].fillna('')\n",
    "comp_names_sim_df['companyname_census'] = comp_names_sim_df['companyname_census'].fillna('')\n",
    "\n",
    "comp_names_sim_df = comp_names_sim_df.rename(columns = {'similarity' : 'names_similarity'})\n",
    "comp_names_sim_df = comp_names_sim_df.drop_duplicates(subset = ['companyname_br', 'companyname_census'])\n",
    "\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['companyname_br', 'companyname_census']).join(\n",
    "    comp_names_sim_df.set_index(['companyname_br', 'companyname_census'])).reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['companyname_br','year']\n",
    "           ).join(no_exact_match_br_census_df[['companyname_br', 'year', 'names_similarity']].groupby(\n",
    "    ['companyname_br', 'year']).max().rename(columns = {'names_similarity' : 'names_max_similarity'}\n",
    "                                        )).reset_index()\n",
    "print(no_exact_match_br_census_df.shape)\n",
    "no_exact_match_br_census_df['names_match'] = no_exact_match_br_census_df.apply(lambda x: True\n",
    "       if (x['names_similarity'] == x['names_max_similarity']) and\n",
    "       (x['names_similarity'] >= 0.85) else False, axis = 1)\n",
    "\n",
    "\n",
    "no_exact_match_br_census_df['names_similarity'] = no_exact_match_br_census_df['names_similarity'].fillna(0)\n",
    "no_exact_match_br_census_df['names_max_similarity'] = no_exact_match_br_census_df['names_max_similarity'].fillna(0)\n",
    "no_exact_match_br_census_df['names_match'] = no_exact_match_br_census_df['names_match'].fillna(False)\n",
    "\n",
    "#extract matched abd unmatched businesses\n",
    "br_match_agg = no_exact_match_br_census_df[['postcode', 'year', 'companyname_br', 'CompanyID_br',\n",
    "         'names_match']].groupby(['postcode', 'year', 'companyname_br', 'CompanyID_br']\n",
    "                ).agg(list)['names_match'].apply(any)\n",
    "\n",
    "census_match_agg = no_exact_match_br_census_df[['postcode', 'year', 'companyname_census', 'CompanyID_census',\n",
    "         'names_match']].groupby(['postcode', 'year', 'companyname_census', 'CompanyID_census']\n",
    "                ).agg(list)['names_match'].apply(any)\n",
    "no_exact_match_br_census_df = no_exact_match_br_census_df.set_index(['postcode', 'year', 'companyname_br',\n",
    "         'CompanyID_br']).join(br_match_agg, rsuffix = '_br').reset_index().set_index(['postcode', 'year',\n",
    "         'companyname_census', 'CompanyID_census']).join(census_match_agg, rsuffix = '_census').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffa2ff-c47d-4e80-98ea-beefb6449cae",
   "metadata": {},
   "source": [
    "# Merge Datasets Based on Matched ant Non-Matched Scnearios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c9978-59d1-4b2c-a25a-c43c3aa0bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_exact_match_br_census_df_match = no_exact_match_br_census_df[no_exact_match_br_census_df['names_match']].copy()\n",
    "br_cols = [c for c in no_exact_match_br_census_df_match.columns if ('_br' in c) and (c != 'comb_address_no_br')] + ['CompanyID_census', 'companyname_census', 'postcode', 'year']\n",
    "no_exact_match_br_census_df_match = no_exact_match_br_census_df_match[br_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_match.columns = [c.replace('_br','').replace('_census','_alt')\n",
    "                                         for c in no_exact_match_br_census_df_match.columns]\n",
    "no_exact_match_br_census_df_match['source'] = 'Both'\n",
    "\n",
    "no_exact_match_br_census_df_br2 = no_exact_match_br_census_df[\n",
    "                        no_exact_match_br_census_df['names_match_br'] == False]\n",
    "br_cols = [c for c in no_exact_match_br_census_df_br2.columns if ('_br' in c and c != 'comb_address_no_br')] + ['postcode', 'year']\n",
    "no_exact_match_br_census_df_br2 = no_exact_match_br_census_df_br2[br_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_br2.columns = [c.replace('_br','') for c in no_exact_match_br_census_df_br2.columns]\n",
    "no_exact_match_br_census_df_br2['source'] = 'BR'\n",
    "\n",
    "no_exact_match_br_census_df_census2 = no_exact_match_br_census_df[no_exact_match_br_census_df['names_match_census'] == False]\n",
    "census_cols = [c for c in no_exact_match_br_census_df_census2.columns if ('_census' in c and c !=\n",
    "                                         'comb_address_no_census')] + ['postcode', 'year']\n",
    "no_exact_match_br_census_df_census2 = no_exact_match_br_census_df_census2[census_cols].drop_duplicates()\n",
    "no_exact_match_br_census_df_census2.columns = [c.replace('_census','') for c in\n",
    "                                              no_exact_match_br_census_df_census2.columns]\n",
    "no_exact_match_br_census_df_census2['source'] = 'Census'\n",
    "\n",
    "print(no_exact_match_br_census_df_match.shape)\n",
    "print(no_exact_match_br_census_df_br2.shape)\n",
    "print(no_exact_match_br_census_df_census2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab128c16-0aad-409c-87d6-931e99020308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exact_match_br_census_df.shape)\n",
    "exact_match_br_census_df = exact_match_br_census_df.set_index(['companyname_br', 'companyname_census']).join(\n",
    "    comp_names_sim_df.set_index(['companyname_br', 'companyname_census'])).reset_index()\n",
    "print(exact_match_br_census_df.shape)\n",
    "print(exact_match_br_census_df[exact_match_br_census_df['names_similarity'].apply(pd.isna)].shape)\n",
    "print(exact_match_br_census_df[~exact_match_br_census_df['names_similarity'].apply(pd.isna)].shape)\n",
    "\n",
    "exact_match_br_census_df = exact_match_br_census_df.set_index(['companyname_br','year']\n",
    "           ).join(exact_match_br_census_df[['companyname_br', 'year', 'names_similarity']].groupby(\n",
    "    ['companyname_br', 'year']).max().rename(columns = {'names_similarity' : 'names_max_similarity'}\n",
    "                                        )).reset_index()\n",
    "print(exact_match_br_census_df.shape)\n",
    "exact_match_br_census_df['names_match'] = exact_match_br_census_df.apply(lambda x: True\n",
    "       if (x['names_similarity'] == x['names_max_similarity']) and\n",
    "       (x['names_similarity'] >= 0.85) else False, axis = 1)\n",
    "\n",
    "br_cols = [c for c in exact_match_br_census_df.columns if ('_br' in c) and (c != 'comb_address_no_br')\n",
    "          ] + ['CompanyID_census', 'companyname_census', 'postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df1 = exact_match_br_census_df[exact_match_br_census_df['names_match']].copy()\n",
    "exact_match_br_census_df1 = exact_match_br_census_df1[br_cols].drop_duplicates()\n",
    "exact_match_br_census_df1.columns = [c.replace('_br','').replace('_census','_alt') for c in\n",
    "                                     exact_match_br_census_df1.columns]\n",
    "exact_match_br_census_df1['source'] = 'Both'\n",
    "print(exact_match_br_census_df1.shape)\n",
    "\n",
    "br_cols = [c for c in exact_match_br_census_df.columns if ('_br' in c and c != 'comb_address_no_br')\n",
    "          ] + ['postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df2 = exact_match_br_census_df[\n",
    "                        exact_match_br_census_df['names_match'] == False]\n",
    "exact_match_br_census_df2 = exact_match_br_census_df2[br_cols].drop_duplicates()\n",
    "exact_match_br_census_df2.columns = [c.replace('_br','') for c in exact_match_br_census_df2.columns]\n",
    "exact_match_br_census_df2['source'] = 'BR'\n",
    "print(exact_match_br_census_df2.shape)\n",
    "\n",
    "census_cols = [c for c in exact_match_br_census_df.columns if ('_census' in c and c != 'comb_address_no_census')\n",
    "          ] + ['postcode', 'year', 'addressline1_merge']\n",
    "\n",
    "exact_match_br_census_df3 = exact_match_br_census_df[\n",
    "                        exact_match_br_census_df['names_match'] == False]\n",
    "exact_match_br_census_df3 = exact_match_br_census_df3[census_cols].drop_duplicates()\n",
    "exact_match_br_census_df3.columns = [c.replace('_census','') for c in exact_match_br_census_df3.columns]\n",
    "exact_match_br_census_df3['source'] = 'Census'\n",
    "print(exact_match_br_census_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a2309-1517-48dd-979a-170850e1ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['CompanyID', 'companyname', 'addressline1', 'postcode', 'dissolutiondate',\n",
    "              'incorporationdate', 'survived', 'year', 'oa21cd', 'lsoa21cd', 'msoa21cd', 'ladnm', 'long', 'lat',\n",
    "              'addressline1_merge', 'scat_sub_category', 'scat_category', 'prev_postcode', 'moved',\n",
    "              'floor_area', 'rental_valuation', 'rates_expected', 'source']\n",
    "final_br_census_df = pd.concat([no_exact_match_br_census_df_census1[final_cols],\n",
    "                           no_exact_match_br_census_df_br1[final_cols],\n",
    "                           no_exact_match_br_census_df_match[final_cols  + ['CompanyID_alt', 'companyname_alt']],\n",
    "                           no_exact_match_br_census_df_br2[final_cols],\n",
    "                           no_exact_match_br_census_df_census2[final_cols],\n",
    "                           exact_match_br_census_df1[final_cols + ['CompanyID_alt', 'companyname_alt']],\n",
    "                           exact_match_br_census_df2[final_cols],\n",
    "                           exact_match_br_census_df3[final_cols]], ignore_index = True)\n",
    "print(final_br_census_df.shape)\n",
    "print(wands_br_lsoa_df.shape)\n",
    "print(wands_year_census_df.shape)\n",
    "print(no_exact_match_br_census_df_match.shape)\n",
    "print(exact_match_br_census_df1.shape)\n",
    "\n",
    "print(final_br_census_df.shape)\n",
    "t = final_br_census_df.groupby(['year', 'CompanyID']).count()[['postcode']].sort_values(by = 'postcode').reset_index()\n",
    "t = t[t['postcode'] > 1].copy().drop(columns = 'postcode')\n",
    "print(t.shape)\n",
    "t['duplicate'] = 'True'\n",
    "tmp = final_br_census_df.set_index(['year', 'CompanyID']).join(t.set_index(['year', 'CompanyID'])\n",
    "                                                              ).reset_index()\n",
    "print(tmp[(tmp['duplicate'].apply(pd.isna))].shape)\n",
    "print(tmp[(~tmp['duplicate'].apply(pd.isna))].shape)\n",
    "print(tmp[(~tmp['duplicate'].apply(pd.isna)) & (tmp['source'] == 'Both')].shape)\n",
    "tmp1 = tmp[tmp['duplicate'].apply(pd.isna)].copy().drop(columns = 'duplicate')\n",
    "tmp2 = tmp[(~tmp['duplicate'].apply(pd.isna)) & (tmp['source'] == 'Both')].copy().drop(columns = 'duplicate')\n",
    "final_br_census_df = pd.concat([tmp1, tmp2], ignore_index = True).sort_values(by = ['CompanyID', 'year'])\n",
    "print(final_br_census_df.shape)\n",
    "final_br_census_df.to_pickle(\"final_br_census_df_v5.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9297d6-fdb3-4ca3-b09e-f53a3e2de1ef",
   "metadata": {},
   "source": [
    "# Plot Moved Business Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdd0b4-1016-40dd-8c96-ce8b4d4172a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_br_census_df = pd.read_pickle(\"final_br_census_df_v5.pkl\")\n",
    "#final_br_census_df['ladnm'] = 'Wandsworth'\n",
    "final_south_br_census_df = pd.read_pickle(\"lam_south_final_br_census_df_v5.pkl\")[final_br_census_df.columns]\n",
    "final_br_census_df = pd.concat([final_br_census_df, final_south_br_census_df[final_south_br_census_df['ladnm']\n",
    "                                == 'Lambeth']], ignore_index = True)\n",
    "final_south_br_census_df = final_south_br_census_df[final_south_br_census_df['ladnm'] == 'Southwark'].copy()\n",
    "\n",
    "#####################\n",
    "moved_final_br_census_df = final_br_census_df[final_br_census_df['moved']].copy()\n",
    "\n",
    "pc_lsoa_mapping_df = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\PCD_OA21_LSOA21.csv\", encoding = \"ISO-8859-1\")\n",
    "ldanm_map_df = pd.read_csv('georef-united-kingdom-local-authority-district.csv', sep = ';')\n",
    "unfound_ladnm_df = {\n",
    "    'Official Name Local authority district': ['Barrow-in-Furness', 'Carlisle', 'Craven', 'Eden', 'Hambleton',\n",
    "              'Harrogate', 'Mendip', 'Pseudo (Channel Islands)', 'Richmondshire',\n",
    "              'Ryedale', 'Scarborough', 'Sedgemoor', 'Selby',\n",
    "              'Somerset West and Taunton', 'South Lakeland', 'South Somerset'],\n",
    "    'Official Name County/Unitary district': ['Cumbria', 'Cumbria', 'North Yorkshire', 'Cumbria', 'North Yorkshire',\n",
    "               'North Yorkshire', 'Somerset', '', 'North Yorkshire',\n",
    "               'North Yorkshire', 'North Yorkshire', 'Somerset', 'North Yorkshire',\n",
    "               'Somerset', 'Cumbria', 'Somerset'],\n",
    "    'Official Name Country': ['England', 'England', 'England', 'England', 'England',\n",
    "                'England', 'England', '', 'England',\n",
    "                'England', 'England', 'England', 'England',\n",
    "                'England', 'England', 'England'],\n",
    "    'Official Name Region': ['North West England', 'North West England', 'Yorkshire and the Humber', 'North West England', 'Yorkshire and the Humber',\n",
    "               'Yorkshire and the Humber', 'South West England', '', 'Yorkshire and the Humber',\n",
    "               'Yorkshire and the Humber', 'Yorkshire and the Humber', 'South West England', 'Yorkshire and the Humber',\n",
    "               'South West England', 'North West England', 'South West England']\n",
    "}\n",
    "unfound_ladnm_df = pd.DataFrame(unfound_ladnm_df)\n",
    "ldanm_map_df = pd.concat([ldanm_map_df, unfound_ladnm_df], ignore_index = True)\n",
    "\n",
    "t = moved_final_br_census_df.set_index('prev_postcode').join(pc_lsoa_mapping_df.rename(\n",
    "    columns = {'pcds' : 'prev_postcode'}).set_index('prev_postcode')[['oa21cd', 'lsoa21cd', 'msoa21cd',\n",
    "            'ladnm']].rename(columns = {'oa21cd' : 'prev_oa21cd', 'lsoa21cd' : 'prev_lsoa21cd', 'msoa21cd' : 'prev_msoa21cd',\n",
    "                                        'ladnm' : 'prev_ladnm'})).reset_index()\n",
    "\n",
    "print(t.shape)\n",
    "print(t[t['prev_ladnm'].apply(pd.isna)].shape)\n",
    "print(t[~t['prev_ladnm'].apply(pd.isna)].shape)\n",
    "\n",
    "t = t.set_index('prev_ladnm').join(ldanm_map_df.rename(columns = {'Official Name Local authority district' : 'prev_ladnm'}).set_index('prev_ladnm')[[\n",
    "                'Official Name Country', 'Official Name Region', 'Official Name County/Unitary district']]).reset_index()\n",
    "t['moved_inside_VNEB'] = t['prev_oa21cd'].apply(lambda x: x in oas_area_wandsworth['oa21cd'].unique())\n",
    "t['moved_inside_borough'] = t['prev_ladnm'].apply(lambda x: x in ['Lambeth', 'Wandsworth'])\n",
    "t['moved_inside_London'] = t['Official Name Region'].apply(lambda x: x in ['London'])\n",
    "print(t.shape)\n",
    "print(t[t['prev_ladnm'].apply(pd.isna)].shape)\n",
    "print(t[~t['prev_ladnm'].apply(pd.isna)].shape)\n",
    "print(t[t['Official Name Country'].apply(pd.isna)].shape)\n",
    "print(t[~t['Official Name Country'].apply(pd.isna)].shape)\n",
    "\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c440729-4f3a-4be2-849a-73322b523c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = t.fillna('').groupby(['year', 'moved_inside_London', 'moved_inside_borough', 'moved_inside_VNEB']).count()[['prev_postcode']\n",
    "            ].reset_index().rename(columns = {'prev_postcode' : 'Moved Business Counts'})\n",
    "test1 = test[test['moved_inside_VNEB']][['year', 'Moved Business Counts']]\n",
    "test1['Moved Type'] = 'From Inside VNEB'\n",
    "test2 = test[(~test['moved_inside_VNEB']) & (test['moved_inside_borough'])][['year', 'Moved Business Counts']]\n",
    "test2['Moved Type'] = 'From Outside VNEB Inside Boroughs'\n",
    "test3 = test[(~test['moved_inside_borough']) & (test['moved_inside_London'])][['year', 'Moved Business Counts']]\n",
    "test3['Moved Type'] = 'From Rest London'\n",
    "test4 = test[(~test['moved_inside_London'])][['year', 'Moved Business Counts']]\n",
    "test4['Moved Type'] = 'From Outside London'\n",
    "final_test = pd.concat([test1, test2, test3, test4], ignore_index = True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa86600-6afa-4e7e-b471-bf8e3f0c7e1d",
   "metadata": {},
   "source": [
    "# Load Opportunity Area and Merge with Business Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55194a46-9c60-4d83-8685-a5243f3b2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "oas = \"Data\\\\OA Boundray\\\\Output_Areas_2021_EW_BFE_V9_-4280877107876255952\\\\OA_2021_EW_BFE_V9.shp\"\n",
    "oas_gdf = gpd.read_file(oas)\n",
    "south_oas_gdf = oas_gdf[oas_gdf['LSOA21NM'].apply(lambda x: ('southwark' in x.lower()))].copy()\n",
    "oas_gdf = oas_gdf[oas_gdf['LSOA21NM'].apply(lambda x: ('wandsworth' in x.lower()) or ('lambeth' in x.lower()))]\n",
    "oas_gdf[\"area_m2\"] = oas_gdf.geometry.area\n",
    "south_oas_gdf[\"area_m2\"] = south_oas_gdf.geometry.area\n",
    "\n",
    "##############\n",
    "ptal_path = \"Data\\\\TFL Data\\\\OneDrive_1_7-19-2025\\\\PTAL data\\\\11.PTAL Data 2023\\\\PTAL_2023_Grid_100m_100m.shp\"\n",
    "ptal_df = gpd.read_file(ptal_path)\n",
    "\n",
    "##############\n",
    "oa_area = 'Data\\\\Opportunity areas boundray\\\\Opportunity_Areas3\\\\Opportunity_Areas.shp'\n",
    "oa_area_gdf = gpd.read_file(oa_area)\n",
    "south_oa_area_gdf = oa_area_gdf[oa_area_gdf['sitename'] == 'Old Kent Road'].copy()\n",
    "wand_oa_area_gdf = oa_area_gdf[oa_area_gdf['borough'] == 'Lambeth,  Wandsworth'].copy()\n",
    "south_oa_area_gdf = south_oa_area_gdf.to_crs(oas_gdf.crs)\n",
    "wand_oa_area_gdf = wand_oa_area_gdf.to_crs(oas_gdf.crs)\n",
    "\n",
    "################\n",
    "oas_area_wandsworth = oas_gdf.sjoin(wand_oa_area_gdf, predicate = 'intersects'\n",
    "                                   ).drop(columns = ['index_right'])\n",
    "oas_area_wandsworth.columns = [c.lower() for c in oas_area_wandsworth.columns]\n",
    "oas_area_wandsworth = oas_area_wandsworth.rename(columns = {'long' : 'oa_long', 'lat' : 'oa_lat'})\n",
    "oas_area_wandsworth = gpd.GeoDataFrame(oas_area_wandsworth,\n",
    "                                   geometry=oas_area_wandsworth['geometry'], crs=\"EPSG:27700\")\n",
    "\n",
    "###############\n",
    "battersea_station = (51.479774, -0.1418745)\n",
    "nine_elms = (51.4799781, -0.1285638)\n",
    "oas_area_wandsworth['battersea_dis'] = oas_area_wandsworth.apply(lambda x:\n",
    "                                         geodesic((x['oa_lat'], x['oa_long']), battersea_station).mi, axis = 1)\n",
    "oas_area_wandsworth['nine_elms_dis'] = oas_area_wandsworth.apply(lambda x:\n",
    "                                         geodesic((x['oa_lat'], x['oa_long']), nine_elms).mi, axis = 1)\n",
    "oas_area_wandsworth['min_dis'] = oas_area_wandsworth.apply(lambda x: min([x['battersea_dis'],\n",
    "                                                  x['nine_elms_dis']]), axis = 1)\n",
    "oas_area_wandsworth['min_dis_station'] = oas_area_wandsworth.apply(lambda x: 'battersea' if\n",
    "                               x['min_dis'] == x['battersea_dis'] else 'nine_elms', axis = 1)\n",
    "oas_area_wandsworth['prox_class'] = oas_area_wandsworth.apply(lambda x: 'prox4'\n",
    "                                  if x['min_dis'] > 1 else 'prox3', axis = 1)\n",
    "oas_area_wandsworth['prox_class'] = oas_area_wandsworth.apply(lambda x: x['prox_class']\n",
    "                                  if x['min_dis'] > 0.5 else 'prox2', axis = 1)\n",
    "oas_area_wandsworth['prox_class'] = oas_area_wandsworth.apply(lambda x: x['prox_class']\n",
    "                                  if x['min_dis'] > 0.25 else 'prox1', axis = 1)\n",
    "\n",
    "###############\n",
    "oas_area_south = south_oas_gdf.sjoin(south_oa_area_gdf, predicate = 'intersects'\n",
    "                                    ).drop(columns = ['index_right'])\n",
    "oas_area_south.columns = [c.lower() for c in oas_area_south.columns]\n",
    "oas_area_south = oas_area_south.rename(columns = {'long' : 'oa_long', 'lat' : 'oa_lat'})\n",
    "oas_area_south = gpd.GeoDataFrame(oas_area_south, geometry=oas_area_south['geometry'], crs=\"EPSG:27700\")\n",
    "oas_area_south['prox_class'] = 'prox4'\n",
    "oas_area_south['min_dis_station'] = np.nan\n",
    "oas_area_south['min_dis'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51649d-67e5-4acd-8141-de530801d84f",
   "metadata": {},
   "source": [
    "# Create rates based on previous run business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933b9d3-5394-40f9-9039-a624d0865b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_br_census_df = pd.read_pickle(\"final_br_census_df_v4.pkl\")\n",
    "final_br_census_df['ladnm'] = 'Wandsworth'\n",
    "final_south_br_census_df = pd.read_pickle(\"lam_south_final_br_census_df_v4.pkl\")[final_br_census_df.columns]\n",
    "final_br_census_df = pd.concat([final_br_census_df, final_south_br_census_df[final_south_br_census_df['ladnm']\n",
    "                                == 'Lambeth']], ignore_index = True)\n",
    "final_south_br_census_df = final_south_br_census_df[final_south_br_census_df['ladnm'] == 'Southwark'].copy()\n",
    "\n",
    "###########################\n",
    "\n",
    "print(final_br_census_df.shape)\n",
    "print(final_south_br_census_df.shape)\n",
    "final_br_census_df = final_br_census_df.set_index('oa21cd').join(\n",
    "    oas_area_wandsworth.set_index('oa21cd')[['sitename', 'area_m2', 'hectares', 'oa_long', 'oa_lat']]).reset_index()\n",
    "final_br_census_oa_df = final_br_census_df[~final_br_census_df['sitename'].apply(pd.isna)]\n",
    "final_south_br_census_df = final_south_br_census_df.set_index('oa21cd').join(\n",
    "    oas_area_south.set_index('oa21cd')[['sitename', 'area_m2', 'hectares', 'oa_long', 'oa_lat']]).reset_index()\n",
    "final_south_br_census_oa_df = final_south_br_census_df[~final_south_br_census_df['sitename'].apply(pd.isna)]\n",
    "\n",
    "final_south_br_census_oa_df['rates_expected_per_area'] = final_south_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rates_expected'] / x['floor_area'], axis = 1)\n",
    "final_br_census_oa_df['rates_expected_per_area'] = final_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rates_expected'] / x['floor_area'], axis = 1)\n",
    "final_south_br_census_oa_df['rental_valuation_per_area'] = final_south_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rental_valuation'] / x['floor_area'], axis = 1)\n",
    "final_br_census_oa_df['rental_valuation_per_area'] = final_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rental_valuation'] / x['floor_area'], axis = 1)\n",
    "\n",
    "final_br_census_oa_df['scat_category'] = final_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_br_census_oa_df['scat_sub_category'] = final_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "final_south_br_census_oa_df['scat_category'] = final_south_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_south_br_census_oa_df['scat_sub_category'] = final_south_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "rates_df = final_br_census_oa_df[['oa21cd', 'year', 'floor_area', 'rental_valuation', 'rates_expected',\n",
    "                       'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year']).mean().reset_index()\n",
    "rates_df['industry'] = 'All'\n",
    "rates_df_cat = final_br_census_oa_df[['oa21cd', 'year', 'scat_category', 'floor_area', 'rental_valuation', 'rates_expected',\n",
    "                   'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year', 'scat_category']\n",
    "                   ).mean().reset_index().rename(columns = {'scat_category' : 'industry'}).copy()\n",
    "rates_df_sub_cat = final_br_census_oa_df[['oa21cd', 'year', 'scat_sub_category', 'floor_area', 'rental_valuation', 'rates_expected',\n",
    "                   'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year', 'scat_sub_category']\n",
    "                   ).mean().reset_index().rename(columns = {'scat_sub_category' : 'industry'}).copy()\n",
    "rates_df = pd.concat([rates_df, rates_df_cat, rates_df_sub_cat], ignore_index = True)\n",
    "rates_df = rates_df.sort_values(by = ['oa21cd', 'year', 'industry'])\n",
    "\n",
    "south_rates_df = final_south_br_census_oa_df[['oa21cd', 'year', 'floor_area', 'rental_valuation', 'rates_expected',\n",
    "                       'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year']).mean().reset_index()\n",
    "south_rates_df['industry'] = 'All'\n",
    "south_rates_df_cat = final_south_br_census_oa_df[['oa21cd', 'year', 'scat_category', 'floor_area', 'rental_valuation',\n",
    "                  'rates_expected', 'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year',\n",
    "                  'scat_category']).mean().reset_index().rename(columns = {'scat_category' : 'industry'}).copy()\n",
    "south_rates_df_sub_cat = final_south_br_census_oa_df[['oa21cd', 'year', 'scat_sub_category', 'floor_area', 'rental_valuation',\n",
    "              'rates_expected', 'rates_expected_per_area', 'rental_valuation_per_area']].groupby(['oa21cd', 'year',\n",
    "                   'scat_sub_category']).mean().reset_index().rename(columns = {'scat_sub_category' : 'industry'}).copy()\n",
    "south_rates_df = pd.concat([south_rates_df, south_rates_df_cat, south_rates_df_sub_cat], ignore_index = True)\n",
    "south_rates_df = south_rates_df.sort_values(by = ['oa21cd', 'year', 'industry'])\n",
    "rates_df.to_pickle(\"oa_rates_df.pkl\")\n",
    "south_rates_df.to_pickle(\"oa_south_rates_df.pkl\")\n",
    "south_rates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb03e72-f169-4efa-8778-f876c18aa676",
   "metadata": {},
   "source": [
    "# Finalise Business Dataset for VNEB and OKR OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c4cc3-d205-458f-a8ea-9463fee504e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_br_census_df = pd.read_pickle(\"final_br_census_df_v5.pkl\")\n",
    "final_south_br_census_df = pd.read_pickle(\"lam_south_final_br_census_df_v5.pkl\")[final_br_census_df.columns]\n",
    "final_br_census_df = pd.concat([final_br_census_df, final_south_br_census_df[final_south_br_census_df['ladnm']\n",
    "                                == 'Lambeth']], ignore_index = True)\n",
    "final_south_br_census_df = final_south_br_census_df[final_south_br_census_df['ladnm'] == 'Southwark'].copy()\n",
    "\n",
    "###########################\n",
    "oa_missing_ptals = {'E00015701' : '6a', 'E00171043' : '3', 'E00171044' : '3', 'E00177504' : '6b',\n",
    "        'E00177572' : '6a', 'E00177582' : '5', 'E00177587' : '5', 'E00177612' : '6a', 'E00177619' : '6a',\n",
    "        'E00183114' : '3', 'E00183164' : '2', 'E00183170' : '3', 'E00183175' : '4'}\n",
    "\n",
    "oas_area_wandsworth_tmp = oas_area_wandsworth.sjoin(ptal_df[['PTAL_2023',\n",
    "                                 'geometry']], predicate=\"intersects\").drop(columns = ['index_right'])\n",
    "print(oas_area_wandsworth_tmp.shape)\n",
    "print(oas_area_wandsworth.shape)\n",
    "print(len(oas_area_wandsworth_tmp['oa21cd'].unique()))\n",
    "print(len(oas_area_wandsworth['oa21cd'].unique()))\n",
    "\n",
    "oas_area_wandsworth_tmp['PTAL_2023'] = oas_area_wandsworth_tmp['PTAL_2023'].apply(str)\n",
    "print(len(oas_area_wandsworth_tmp))\n",
    "oas_area_wandsworth_tmp_ptal2023 = oas_area_wandsworth_tmp.groupby('oa21cd').agg(list)[['PTAL_2023']]\n",
    "\n",
    "oas_area_wandsworth_tmp_ptal2023['PTAL_2023'] = oas_area_wandsworth_tmp_ptal2023['PTAL_2023'].apply(lambda x:\n",
    "                                     pd.Series(x).sort_values(ascending = False).tolist())\n",
    "oas_area_wandsworth_tmp_ptal2023['PTAL_2023'] = oas_area_wandsworth_tmp_ptal2023['PTAL_2023'].apply(\n",
    "    lambda x: {c:Counter(x)[c] / len(x) for c in Counter(x)})\n",
    "oas_area_wandsworth_tmp_ptal2023['PTAL2023_main'] = oas_area_wandsworth_tmp_ptal2023['PTAL_2023'].apply(\n",
    "    lambda x: max(x, key = x.get))\n",
    "\n",
    "oas_area_wandsworth = oas_area_wandsworth.set_index('oa21cd').join(oas_area_wandsworth_tmp_ptal2023).reset_index()\n",
    "print(oas_area_wandsworth.shape)\n",
    "\n",
    "oas_area_south_tmp = oas_area_south.sjoin(ptal_df[['PTAL_2023',\n",
    "                                 'geometry']], predicate=\"intersects\").drop(columns = ['index_right'])\n",
    "print(oas_area_south_tmp.shape)\n",
    "print(oas_area_south.shape)\n",
    "print(len(oas_area_south_tmp['oa21cd'].unique()))\n",
    "print(len(oas_area_south['oa21cd'].unique()))\n",
    "\n",
    "oas_area_south_tmp['PTAL_2023'] = oas_area_south_tmp['PTAL_2023'].apply(str)\n",
    "print(len(oas_area_south_tmp))\n",
    "oas_area_south_tmp_ptal2023 = oas_area_south_tmp.groupby('oa21cd').agg(list)[['PTAL_2023']]\n",
    "\n",
    "oas_area_south_tmp_ptal2023['PTAL_2023'] = oas_area_south_tmp_ptal2023['PTAL_2023'].apply(lambda x:\n",
    "                                     pd.Series(x).sort_values(ascending = False).tolist())\n",
    "oas_area_south_tmp_ptal2023['PTAL_2023'] = oas_area_south_tmp_ptal2023['PTAL_2023'].apply(\n",
    "    lambda x: {c:Counter(x)[c] / len(x) for c in Counter(x)})\n",
    "oas_area_south_tmp_ptal2023['PTAL2023_main'] = oas_area_south_tmp_ptal2023['PTAL_2023'].apply(\n",
    "    lambda x: max(x, key = x.get))\n",
    "\n",
    "oas_area_south = oas_area_south.set_index('oa21cd').join(oas_area_south_tmp_ptal2023).reset_index()\n",
    "print(oas_area_south.shape)\n",
    "\n",
    "##############################\n",
    "print(final_br_census_df.shape)\n",
    "print(final_south_br_census_df.shape)\n",
    "final_br_census_df = final_br_census_df.set_index('oa21cd').join(\n",
    "    oas_area_wandsworth.set_index('oa21cd')[['sitename', 'area_m2', 'hectares', 'oa_long', 'oa_lat',\n",
    "                                            'PTAL2023_main', 'prox_class']]).reset_index()\n",
    "final_br_census_oa_df = final_br_census_df[~final_br_census_df['sitename'].apply(pd.isna)]\n",
    "final_south_br_census_df = final_south_br_census_df.set_index('oa21cd').join(\n",
    "    oas_area_south.set_index('oa21cd')[['sitename', 'area_m2', 'hectares', 'oa_long', 'oa_lat',\n",
    "                                       'PTAL2023_main', 'prox_class']]).reset_index()\n",
    "final_south_br_census_oa_df = final_south_br_census_df[~final_south_br_census_df['sitename'].apply(pd.isna)]\n",
    "final_br_census_oa_df['new_business'] = final_br_census_oa_df.apply(lambda x:\n",
    "                            parse(x['incorporationdate']).year == x['year'], axis = 1)\n",
    "final_br_census_oa_df['dissolved_business'] = final_br_census_oa_df.apply(lambda x: False if\n",
    "                  pd.isna(x['dissolutiondate']) else parse(x['dissolutiondate']).year == x['year'], axis = 1)\n",
    "final_south_br_census_oa_df['new_business'] = final_south_br_census_oa_df.apply(lambda x:\n",
    "                    parse(x['incorporationdate']).year == x['year'] if isinstance(x['incorporationdate'], str)\n",
    "                    else x['incorporationdate'].year == x['year'], axis = 1)\n",
    "final_south_br_census_oa_df['dissolved_business'] = final_south_br_census_oa_df.apply(lambda x: False if\n",
    "                  pd.isna(x['dissolutiondate']) else parse(x['dissolutiondate']).year == x['year'], axis = 1)\n",
    "print(final_br_census_df.shape)\n",
    "print(final_br_census_oa_df.shape)\n",
    "print(final_south_br_census_df.shape)\n",
    "print(final_south_br_census_oa_df.shape)\n",
    "final_br_census_oa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc082a-5001-4d22-97ae-ac8377d84276",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df1 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\SE postcodes.csv\")\n",
    "pc_df2 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\SW postcodes.csv\")\n",
    "pc_df3 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\CR postcodes.csv\")\n",
    "pc_long_lat_df = pd.concat([pc_df1, pc_df2, pc_df3], ignore_index = True).rename(columns = {'Postcode' : 'postcode',\n",
    "                                       'Latitude' : 'pc_lat', 'Longitude' : 'pc_long'})[['postcode', 'pc_lat', 'pc_long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c207c8e-a7ff-4fdf-baa4-f4523bdc1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_br_census_oa_df.shape)\n",
    "final_br_census_oa_df = final_br_census_oa_df.set_index('postcode').join(pc_long_lat_df.set_index('postcode')).reset_index()\n",
    "print(final_br_census_oa_df.shape)\n",
    "print(final_br_census_oa_df[final_br_census_oa_df['pc_long'].apply(pd.isna)].shape)\n",
    "final_br_census_oa_df['lat'] = final_br_census_oa_df.apply(lambda x: x['lat'] if not pd.isna(x['lat'])\n",
    "                                                           else x['pc_lat'], axis = 1)\n",
    "final_br_census_oa_df['long'] = final_br_census_oa_df.apply(lambda x: x['long'] if not pd.isna(x['long'])\n",
    "                                                           else x['pc_long'], axis = 1)\n",
    "\n",
    "####################\n",
    "battersea_station = (51.479774, -0.1418745)\n",
    "nine_elms = (51.4799781, -0.1285638)\n",
    "final_br_census_oa_df['battersea_dis'] = final_br_census_oa_df.apply(lambda x:\n",
    "                                         geodesic((x['lat'], x['long']), battersea_station).mi, axis = 1)\n",
    "final_br_census_oa_df['nine_elms_dis'] = final_br_census_oa_df.apply(lambda x:\n",
    "                                         geodesic((x['lat'], x['long']), nine_elms).mi, axis = 1)\n",
    "final_br_census_oa_df['min_dis'] = final_br_census_oa_df.apply(lambda x: min([x['battersea_dis'],\n",
    "                                                  x['nine_elms_dis']]), axis = 1)\n",
    "final_br_census_oa_df['bus_prox_class'] = final_br_census_oa_df.apply(lambda x: 'prox4'\n",
    "                                  if x['min_dis'] > 1 else 'prox3', axis = 1)\n",
    "final_br_census_oa_df['bus_prox_class'] = final_br_census_oa_df.apply(lambda x: x['bus_prox_class']\n",
    "                                  if x['min_dis'] > 0.5 else 'prox2', axis = 1)\n",
    "final_br_census_oa_df['bus_prox_class'] = final_br_census_oa_df.apply(lambda x: x['bus_prox_class']\n",
    "                                  if x['min_dis'] > 0.25 else 'prox1', axis = 1)\n",
    "final_br_census_oa_df = final_br_census_oa_df.sort_values(by = ['CompanyID', 'year'])\n",
    "final_br_census_oa_df['prev_bus_prox_class'] = final_br_census_oa_df.groupby('CompanyID')['bus_prox_class'].shift()\n",
    "final_br_census_oa_df['prox_moved_closer'], final_br_census_oa_df['prox_moved_further'], \\\n",
    "   final_br_census_oa_df['prox_moved_same'] = zip(*final_br_census_oa_df.apply(get_moved, axis = 1))\n",
    "\n",
    "final_br_census_oa_df = gpd.GeoDataFrame(\n",
    "    final_br_census_oa_df, geometry=gpd.points_from_xy(final_br_census_oa_df['long'],\n",
    "                                               final_br_census_oa_df['lat']), crs=\"EPSG:4326\")\n",
    "final_br_census_oa_df = final_br_census_oa_df.to_crs(epsg=27700)\n",
    "final_br_census_oa_df = final_br_census_oa_df.sjoin(ptal_df[['PTAL_2023','geometry']].rename(\n",
    "    columns = {'PTAL_2023' : 'bus_PTAL_2023'}), predicate=\"intersects\").drop(columns = ['index_right'])\n",
    "final_br_census_oa_df['bus_PTAL_2023'] = final_br_census_oa_df['bus_PTAL_2023'].apply(str)\n",
    "final_br_census_oa_df = final_br_census_oa_df.sort_values(by = ['CompanyID', 'year'])\n",
    "final_br_census_oa_df['prev_bus_PTAL_2023'] = final_br_census_oa_df.groupby('CompanyID')['bus_PTAL_2023'].shift()\n",
    "final_br_census_oa_df['PTAL_moved_closer'], final_br_census_oa_df['PTAL_moved_further'], \\\n",
    "   final_br_census_oa_df['PTAL_moved_same'] = zip(*final_br_census_oa_df.apply(lambda x: get_moved(x,\n",
    "                                                               col = 'bus_PTAL_2023'), axis = 1))\n",
    "\n",
    "final_br_census_oa_df['prev_oa21cd'] = final_br_census_oa_df.groupby('CompanyID')['oa21cd'].shift()\n",
    "final_br_census_oa_df['moved_within'] = final_br_census_oa_df.apply(get_moved_within, axis = 1)\n",
    "\n",
    "final_br_census_oa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ee844-06c1-48ba-86b2-aafc01310346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_south_br_census_oa_df.shape)\n",
    "final_south_br_census_oa_df = final_south_br_census_oa_df.set_index('postcode').join(pc_long_lat_df.set_index('postcode')\n",
    "                                                                                    ).reset_index()\n",
    "print(final_south_br_census_oa_df.shape)\n",
    "print(final_south_br_census_oa_df[final_south_br_census_oa_df['pc_long'].apply(pd.isna)].shape)\n",
    "final_south_br_census_oa_df['lat'] = final_south_br_census_oa_df.apply(lambda x: x['lat'] if not pd.isna(x['lat'])\n",
    "                                                           else x['pc_lat'], axis = 1)\n",
    "final_south_br_census_oa_df['long'] = final_south_br_census_oa_df.apply(lambda x: x['long'] if not pd.isna(x['long'])\n",
    "                                                           else x['pc_long'], axis = 1)\n",
    "\n",
    "####################\n",
    "\n",
    "final_south_br_census_oa_df['battersea_dis'] = np.nan\n",
    "final_south_br_census_oa_df['nine_elms_dis'] = np.nan\n",
    "final_south_br_census_oa_df['min_dis'] = np.nan\n",
    "final_south_br_census_oa_df['bus_prox_class'] = 'prox4'\n",
    "final_south_br_census_oa_df['prev_bus_prox_class'] = 'prox4'\n",
    "final_south_br_census_oa_df['prox_moved_closer'], final_south_br_census_oa_df['prox_moved_further'], \\\n",
    "   final_south_br_census_oa_df['prox_moved_same'] = zip(*final_south_br_census_oa_df.apply(get_moved, axis = 1))\n",
    "\n",
    "final_south_br_census_oa_df = gpd.GeoDataFrame(\n",
    "    final_south_br_census_oa_df, geometry=gpd.points_from_xy(final_south_br_census_oa_df['long'],\n",
    "                                               final_south_br_census_oa_df['lat']), crs=\"EPSG:4326\")\n",
    "final_south_br_census_oa_df = final_south_br_census_oa_df.to_crs(epsg=27700)\n",
    "final_south_br_census_oa_df = final_south_br_census_oa_df.sjoin(ptal_df[['PTAL_2023','geometry']].rename(\n",
    "    columns = {'PTAL_2023' : 'bus_PTAL_2023'}), predicate=\"intersects\").drop(columns = ['index_right'])\n",
    "final_south_br_census_oa_df['bus_PTAL_2023'] = final_south_br_census_oa_df['bus_PTAL_2023'].apply(str)\n",
    "final_south_br_census_oa_df = final_south_br_census_oa_df.sort_values(by = ['CompanyID', 'year'])\n",
    "final_south_br_census_oa_df['prev_bus_PTAL_2023'] = final_south_br_census_oa_df.groupby('CompanyID')['bus_PTAL_2023'].shift()\n",
    "final_south_br_census_oa_df['PTAL_moved_closer'], final_south_br_census_oa_df['PTAL_moved_further'], \\\n",
    "   final_south_br_census_oa_df['PTAL_moved_same'] = zip(*final_south_br_census_oa_df.apply(lambda x: get_moved(x,\n",
    "                                                               col = 'bus_PTAL_2023'), axis = 1))\n",
    "\n",
    "final_south_br_census_oa_df['prev_oa21cd'] = final_south_br_census_oa_df.groupby('CompanyID')['oa21cd'].shift()\n",
    "final_south_br_census_oa_df['moved_within'] = final_south_br_census_oa_df.apply(get_moved_within, axis = 1)\n",
    "\n",
    "final_br_census_oa_df['rates_expected_per_area'] = final_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rates_expected'] / x['floor_area'], axis = 1)\n",
    "final_br_census_oa_df['rental_valuation_per_area'] = final_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rental_valuation'] / x['floor_area'], axis = 1)\n",
    "final_south_br_census_oa_df['rates_expected_per_area'] = final_south_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rates_expected'] / x['floor_area'], axis = 1)\n",
    "final_south_br_census_oa_df['rental_valuation_per_area'] = final_south_br_census_oa_df.apply(lambda x: np.nan\n",
    "                       if pd.isna(x['floor_area']) else x['rental_valuation'] / x['floor_area'], axis = 1)\n",
    "\n",
    "final_br_census_oa_df['scat_category'] = final_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_br_census_oa_df['scat_sub_category'] = final_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "final_south_br_census_oa_df['scat_category'] = final_south_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_south_br_census_oa_df['scat_sub_category'] = final_south_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "final_br_census_oa_df.to_pickle(\"final_br_census_oa_df_v3.pkl\")\n",
    "final_south_br_census_oa_df.to_pickle(\"final_south_br_census_oa_df_v3.pkl\")\n",
    "\n",
    "final_south_br_census_oa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8625ba-74ca-4d69-9871-a9d50443d37b",
   "metadata": {},
   "source": [
    "# Calculate Agglomeration Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4def3d-2040-4907-bd70-57573e3f1c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "t = final_br_census_oa_df.copy()\n",
    "t['coords'] = t.apply(lambda x:(x['pc_lat'], x['pc_long']), axis = 1)\n",
    "t = t[['oa21cd', 'year', 'pc_long', 'pc_lat', 'coords']].groupby(['oa21cd', 'year']).agg({'pc_long' : np.mean, 'pc_lat' : np.mean,\n",
    "                                                     'coords' : list}).reset_index()\n",
    "t['industry'] = 'All'\n",
    "t['cent_distances'] = t.apply(lambda x: [geodesic((x['pc_lat'], x['pc_long']), c).m for c in x['coords']], axis = 1)\n",
    "t['cent_mean_dis'] = t['cent_distances'].apply(np.mean)\n",
    "\n",
    "final_agg_distance = [t]\n",
    "\n",
    "industry_details = {'scat_category' : final_br_census_oa_df['scat_category'].unique().tolist(),\n",
    " 'scat_sub_category' : final_br_census_oa_df['scat_sub_category'].unique().tolist()}\n",
    "for industry_col in industry_details:\n",
    "    for industry in industry_details[industry_col]:\n",
    "        tmp = final_br_census_oa_df[final_br_census_oa_df[industry_col] == industry].copy()\n",
    "        tmp['coords'] = tmp.apply(lambda x:(x['pc_lat'], x['pc_long']), axis = 1)\n",
    "        tmp = tmp[['oa21cd', 'year', 'pc_long', 'pc_lat', 'coords']].groupby(['oa21cd', 'year']).agg({'pc_long' : np.mean, 'pc_lat' : np.mean,\n",
    "                                                             'coords' : list}).reset_index()\n",
    "        tmp['industry'] = industry\n",
    "        tmp['cent_distances'] = tmp.apply(lambda x: [geodesic((x['pc_lat'], x['pc_long']), c).m for c in x['coords']], axis = 1)\n",
    "        tmp['cent_mean_dis'] = tmp['cent_distances'].apply(np.mean)\n",
    "        final_agg_distance.append(tmp)\n",
    "\n",
    "final_agg_distance = pd.concat(final_agg_distance, ignore_index = True)\n",
    "\n",
    "############################\n",
    "t = final_south_br_census_oa_df.copy()\n",
    "t['coords'] = t.apply(lambda x:(x['pc_lat'], x['pc_long']), axis = 1)\n",
    "t = t[['oa21cd', 'year', 'pc_long', 'pc_lat', 'coords']].groupby(['oa21cd', 'year']).agg({'pc_long' : np.mean, 'pc_lat' : np.mean,\n",
    "                                                     'coords' : list}).reset_index()\n",
    "t['industry'] = 'All'\n",
    "t['cent_distances'] = t.apply(lambda x: [geodesic((x['pc_lat'], x['pc_long']), c).m for c in x['coords']], axis = 1)\n",
    "t['cent_mean_dis'] = t['cent_distances'].apply(np.mean)\n",
    "\n",
    "final_south_agg_distance = [t]\n",
    "\n",
    "industry_details = {'scat_category' : final_south_br_census_oa_df['scat_category'].unique().tolist(),\n",
    " 'scat_sub_category' : final_south_br_census_oa_df['scat_sub_category'].unique().tolist()}\n",
    "for industry_col in industry_details:\n",
    "    for industry in industry_details[industry_col]:\n",
    "        tmp = final_south_br_census_oa_df[final_south_br_census_oa_df[industry_col] == industry].copy()\n",
    "        tmp['coords'] = tmp.apply(lambda x:(x['pc_lat'], x['pc_long']), axis = 1)\n",
    "        tmp = tmp[['oa21cd', 'year', 'pc_long', 'pc_lat', 'coords']].groupby(['oa21cd', 'year']).agg({'pc_long' : np.mean, 'pc_lat' : np.mean,\n",
    "                                                             'coords' : list}).reset_index()\n",
    "        tmp['industry'] = industry\n",
    "        tmp['cent_distances'] = tmp.apply(lambda x: [geodesic((x['pc_lat'], x['pc_long']), c).m for c in x['coords']], axis = 1)\n",
    "        tmp['cent_mean_dis'] = tmp['cent_distances'].apply(np.mean)\n",
    "        final_south_agg_distance.append(tmp)\n",
    "\n",
    "final_south_agg_distance = pd.concat(final_south_agg_distance, ignore_index = True)\n",
    "\n",
    "final_agg_distance.to_pickle(\"final_agg_distance_v3.pkl\")\n",
    "final_south_agg_distance.to_pickle(\"final_south_agg_distance_v3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53861e-0d49-430a-ab85-6c422e7730d7",
   "metadata": {},
   "source": [
    "# OA Businesses Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f7d85-b43f-4490-89b8-2f9d01a30a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OA Businesses Aggregation\n",
    "final_br_census_oa_df['scat_category'] = final_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_br_census_oa_df['scat_sub_category'] = final_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "br_census_df = final_br_census_oa_df.copy()\n",
    "industry_details = {'scat_category' : br_census_df['scat_category'].unique().tolist(),\n",
    " 'scat_sub_category' : br_census_df['scat_sub_category'].unique().tolist()}\n",
    "\n",
    "oas = br_census_df['oa21cd'].unique().tolist()\n",
    "years = br_census_df['year'].unique().tolist()\n",
    "oa_final_df = []\n",
    "\n",
    "for oa in oas:\n",
    "    print(f\"Processing oa {oa} with time is {str(datetime.datetime.now())}\")\n",
    "    oa_m2 = br_census_df[br_census_df['oa21cd'] == oa]['area_m2'].iloc[0]\n",
    "    oa_ladnm = br_census_df[br_census_df['oa21cd'] == oa]['ladnm'].iloc[0]\n",
    "    oa_plat2023 = br_census_df[br_census_df['oa21cd'] == oa]['PTAL2023_main'].iloc[0]\n",
    "    oa_prox = br_census_df[br_census_df['oa21cd'] == oa]['prox_class'].iloc[0]\n",
    "    oa_lat = br_census_df[br_census_df['oa21cd'] == oa]['oa_lat'].iloc[0]\n",
    "    oa_long = br_census_df[br_census_df['oa21cd'] == oa]['oa_long'].iloc[0]\n",
    "    for year in years:\n",
    "        tmp = br_census_df[(br_census_df['oa21cd'] == oa) & (br_census_df['year'] == year)\n",
    "                                ].copy()\n",
    "        census_total = len(tmp[tmp['source'] == 'Census'])\n",
    "        census_total = census_total if census_total else np.nan\n",
    "        br_total = len(tmp[tmp['source'] == 'BR'])\n",
    "        br_total = br_total if br_total else np.nan\n",
    "        both_total = len(tmp[tmp['source'] == 'Both'])\n",
    "        both_total = both_total if both_total else np.nan\n",
    "        total = len(tmp)\n",
    "        survival_count = len(tmp[(tmp['survived'])])\n",
    "        survival_rate = survival_count / total if total else 0\n",
    "        new_count = len(tmp[(tmp['new_business'])]) \n",
    "        new_rate = new_count / total if total else 0\n",
    "        moved_count = len(tmp[(tmp['moved'])])\n",
    "        moved_rate = moved_count / total if total else 0\n",
    "        moved_within_count = len(tmp[(tmp['moved']) & (tmp['moved_within'])])\n",
    "        moved_within_rate = moved_within_count / total if total else 0\n",
    "        moved_outside_count = len(tmp[(tmp['moved']) & (~tmp['moved_within'])])\n",
    "        moved_outside_rate = moved_outside_count / total if total else 0\n",
    "        \n",
    "        PTAL_moved_closer_count = len(tmp[(tmp['PTAL_moved_closer'])])\n",
    "        PTAL_moved_closer_rate = PTAL_moved_closer_count / total if total else 0\n",
    "        PTAL_moved_further_count = len(tmp[(tmp['PTAL_moved_further'])])\n",
    "        PTAL_moved_further_rate = PTAL_moved_further_count / total if total else 0\n",
    "        PTAL_moved_same_count = len(tmp[(tmp['PTAL_moved_same'])])\n",
    "        PTAL_moved_same_rate = PTAL_moved_same_count / total if total else 0\n",
    "        prox_moved_closer_count = len(tmp[(tmp['prox_moved_closer'])])\n",
    "        prox_moved_closer_rate = prox_moved_closer_count / total if total else 0\n",
    "        prox_moved_further_count = len(tmp[(tmp['prox_moved_further'])])\n",
    "        prox_moved_further_rate = prox_moved_further_count / total if total else 0\n",
    "        prox_moved_same_count = len(tmp[(tmp['prox_moved_same'])])\n",
    "        prox_moved_same_rate = prox_moved_same_count / total if total else 0\n",
    "        dissolved_count = len(tmp[(tmp['dissolved_business'])])\n",
    "        dissolved_rate = dissolved_count / total if total else 0\n",
    "        rates_expected_mean = tmp['rates_expected'].mean()\n",
    "        rental_valuation_mean = tmp['rental_valuation'].mean()\n",
    "        floor_area_mean = tmp['floor_area'].mean()\n",
    "        rates_expected_per_area_mean = tmp['rates_expected_per_area'].mean()\n",
    "        rental_valuation_per_area_mean = tmp['rental_valuation_per_area'].mean()\n",
    "        rates_expected_std = tmp['rates_expected'].std()\n",
    "        rental_valuation_std = tmp['rental_valuation'].std()\n",
    "        floor_area_std = tmp['floor_area'].std()\n",
    "        \n",
    "        oa_dic = {'oa21cd' : [oa], 'year' : [year], 'area_m2' : [oa_m2], 'oa_ladnm' : [oa_ladnm],\n",
    "      'oa_plat2023' : [oa_plat2023], 'oa_prox' : [oa_prox],\n",
    "      'oa_lat' : [oa_lat], 'oa_long' : [oa_long], 'bus_count_actual' : [total],\n",
    "      'census_bus_count' : [census_total], 'br_bus_count' : [br_total], 'both_bus_count' : [both_total],\n",
    "      'survival_rate' : [survival_rate], 'new_rate' : [new_rate], 'moved_rate' : [moved_rate],\n",
    "      'moved_within_rate' : [moved_within_rate],  'moved_outside_rate' : [moved_outside_rate],\n",
    "      'dissolved_rate' : [dissolved_rate], 'PTAL_moved_closer_rate' : [PTAL_moved_closer_rate],\n",
    "      'PTAL_moved_further_rate' : [PTAL_moved_further_rate], 'PTAL_moved_same_rate' : [PTAL_moved_same_rate],\n",
    "      'prox_moved_closer_rate' : [prox_moved_closer_rate],\n",
    "      'prox_moved_further_rate' : [prox_moved_further_rate], 'prox_moved_same_rate' : [prox_moved_same_rate],\n",
    "      'survival_count' : [survival_count], 'new_count' : [new_count],\n",
    "      'moved_count' : [moved_count], 'moved_within_count' : [moved_within_count],  'moved_outside_count' : [moved_outside_count],\n",
    "      'dissolved_count' : [dissolved_count], 'PTAL_moved_closer_count' : [PTAL_moved_closer_count],\n",
    "      'PTAL_moved_further_count' : [PTAL_moved_further_count], 'PTAL_moved_same_count' : [PTAL_moved_same_count],\n",
    "      'prox_moved_closer_count' : [prox_moved_closer_count],\n",
    "      'prox_moved_further_count' : [prox_moved_further_count], 'prox_moved_same_count' : [prox_moved_same_count],\n",
    "      'rates_expected_mean' : [rates_expected_mean],\n",
    "      'rental_valuation_mean' : [rental_valuation_mean], 'floor_area_mean' : [floor_area_mean],\n",
    "      'rates_expected_per_area_mean' : [rates_expected_per_area_mean], 'rental_valuation_per_area_mean' : [rental_valuation_per_area_mean],\n",
    "      'rates_expected_std' : [rates_expected_std], 'rental_valuation_std' : [rental_valuation_std],\n",
    "      'floor_area_std' : [floor_area_std], 'industry' : ['All']\n",
    "              }\n",
    "        oa_final_df.append(pd.DataFrame(oa_dic))\n",
    "        for industry_col in industry_details:\n",
    "            for industry in industry_details[industry_col]:\n",
    "                tmp = br_census_df[(br_census_df['oa21cd'] == oa) &\n",
    "                                         (br_census_df['year'] == year) &\n",
    "                                         (br_census_df[industry_col] == industry)].copy()\n",
    "                census_total = len(tmp[tmp['source'] == 'Census'])\n",
    "                census_total = census_total if total else np.nan\n",
    "                br_total = len(tmp[tmp['source'] == 'BR'])\n",
    "                br_total = br_total if total else np.nan\n",
    "                both_total = len(tmp[tmp['source'] == 'Both'])\n",
    "                both_total = both_total if total else np.nan\n",
    "                indus_total = len(tmp)\n",
    "                survival_count = len(tmp[(tmp['survived'])])\n",
    "                survival_rate = survival_count / indus_total if indus_total else 0\n",
    "                new_count = len(tmp[(tmp['new_business'])]) \n",
    "                new_rate = new_count / indus_total if indus_total else 0\n",
    "                moved_count = len(tmp[(tmp['moved'])])\n",
    "                moved_rate = moved_count / indus_total if indus_total else 0\n",
    "                moved_within_count = len(tmp[(tmp['moved']) & (tmp['moved_within'])])\n",
    "                moved_within_rate = moved_within_count / indus_total if indus_total else 0\n",
    "                moved_outside_count = len(tmp[(tmp['moved']) & (~tmp['moved_within'])])\n",
    "                moved_outside_rate = moved_outside_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_closer_count = len(tmp[(tmp['PTAL_moved_closer'])])\n",
    "                PTAL_moved_closer_rate = PTAL_moved_closer_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_further_count = len(tmp[(tmp['PTAL_moved_further'])])\n",
    "                PTAL_moved_further_rate = PTAL_moved_further_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_same_count = len(tmp[(tmp['PTAL_moved_same'])])\n",
    "                PTAL_moved_same_rate = PTAL_moved_same_count / indus_total if indus_total else 0\n",
    "                prox_moved_closer_count = len(tmp[(tmp['prox_moved_closer'])])\n",
    "                prox_moved_closer_rate = prox_moved_closer_count / indus_total if indus_total else 0\n",
    "                prox_moved_further_count = len(tmp[(tmp['prox_moved_further'])])\n",
    "                prox_moved_further_rate = prox_moved_further_count / indus_total if indus_total else 0\n",
    "                prox_moved_same_count = len(tmp[(tmp['prox_moved_same'])])\n",
    "                prox_moved_same_rate = prox_moved_same_count / indus_total if indus_total else 0\n",
    "                dissolved_count = len(tmp[(tmp['dissolved_business'])])\n",
    "                dissolved_rate = dissolved_count / indus_total if indus_total else 0\n",
    "                rates_expected_mean = tmp['rates_expected'].mean()\n",
    "                rental_valuation_mean = tmp['rental_valuation'].mean()\n",
    "                rates_expected_per_area_mean = tmp['rates_expected_per_area'].mean()\n",
    "                rental_valuation_per_area_mean = tmp['rental_valuation_per_area'].mean()\n",
    "                floor_area_mean = tmp['floor_area'].mean()\n",
    "                rates_expected_std = tmp['rates_expected'].std()\n",
    "                rental_valuation_std = tmp['rental_valuation'].std()\n",
    "                floor_area_std = tmp['floor_area'].std()\n",
    "                \n",
    "                oa_dic = {'oa21cd' : [oa], 'year' : [year], 'area_m2' : [oa_m2], 'oa_ladnm' : [oa_ladnm],\n",
    "      'oa_plat2023' : [oa_plat2023], 'oa_prox' : [oa_prox],\n",
    "      'oa_lat' : [oa_lat], 'oa_long' : [oa_long], 'bus_count_actual' : [indus_total],\n",
    "      'census_bus_count' : [census_total], 'br_bus_count' : [br_total], 'both_bus_count' : [both_total],\n",
    "      'survival_rate' : [survival_rate], 'new_rate' : [new_rate], 'moved_rate' : [moved_rate],\n",
    "      'moved_within_rate' : [moved_within_rate],  'moved_outside_rate' : [moved_outside_rate],\n",
    "      'dissolved_rate' : [dissolved_rate], 'PTAL_moved_closer_rate' : [PTAL_moved_closer_rate],\n",
    "      'PTAL_moved_further_rate' : [PTAL_moved_further_rate], 'PTAL_moved_same_rate' : [PTAL_moved_same_rate],\n",
    "      'prox_moved_closer_rate' : [prox_moved_closer_rate],\n",
    "      'prox_moved_further_rate' : [prox_moved_further_rate], 'prox_moved_same_rate' : [prox_moved_same_rate],\n",
    "      'survival_count' : [survival_count], 'new_count' : [new_count],\n",
    "      'moved_count' : [moved_count], 'moved_within_count' : [moved_within_count],  'moved_outside_count' : [moved_outside_count],\n",
    "      'dissolved_count' : [dissolved_count], 'PTAL_moved_closer_count' : [PTAL_moved_closer_count],\n",
    "      'PTAL_moved_further_count' : [PTAL_moved_further_count], 'PTAL_moved_same_count' : [PTAL_moved_same_count],\n",
    "      'prox_moved_closer_count' : [prox_moved_closer_count],\n",
    "      'prox_moved_further_count' : [prox_moved_further_count], 'prox_moved_same_count' : [prox_moved_same_count],\n",
    "      'rates_expected_mean' : [rates_expected_mean],\n",
    "      'rental_valuation_mean' : [rental_valuation_mean], 'floor_area_mean' : [floor_area_mean],\n",
    "      'rates_expected_per_area_mean' : [rates_expected_per_area_mean], 'rental_valuation_per_area_mean' : [rental_valuation_per_area_mean],\n",
    "      'rates_expected_std' : [rates_expected_std], 'rental_valuation_std' : [rental_valuation_std],\n",
    "      'floor_area_std' : [floor_area_std], 'industry' : [industry]\n",
    "              }\n",
    "                oa_final_df.append(pd.DataFrame(oa_dic))\n",
    "group_cols = ['oa21cd', 'industry']\n",
    "oa_final_df = pd.concat(oa_final_df, ignore_index = True).sort_values(by = ['oa21cd', 'year'])\n",
    "oa_final_df['census_bus_count'] = oa_final_df.groupby(group_cols)['census_bus_count'].bfill().fillna(0)\n",
    "oa_final_df['br_bus_count'] = oa_final_df['br_bus_count'].fillna(0)\n",
    "oa_final_df['both_bus_count'] = oa_final_df.groupby(group_cols)['both_bus_count'].bfill().fillna(0)\n",
    "oa_final_df['bus_count'] = oa_final_df['census_bus_count'] + oa_final_df['br_bus_count'] \\\n",
    "                                + oa_final_df['both_bus_count']\n",
    "oa_final_df.to_pickle(\"VNEB_oa_final_df_v5.pkl\")\n",
    "oa_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75d269-22d5-4e50-8c51-7de61c84f6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OA Businesses Aggregation\n",
    "\n",
    "final_south_br_census_oa_df['scat_category'] = final_south_br_census_oa_df['scat_category'].apply(lambda x: x.title())\n",
    "final_south_br_census_oa_df['scat_sub_category'] = final_south_br_census_oa_df['scat_sub_category'].apply(lambda x: x.replace(\"OFFICE_DATA_CENTRES\",\n",
    "       \"Office IT / Data Centres\").replace(\"RETAIL_OTHER_SUPERSTORES_AND_WAREHOUSES\", \"Retail Other Superstores/ Retail Warehouses\"\n",
    "       ).replace(\"LEISURE_GENERAL_HOTELS\", \"Leisure General Hotels (3 star)\").replace(\"&\", \"and\").replace(\"  \", \" \").replace(\n",
    "    \"_\", \" \").title())\n",
    "\n",
    "br_census_df = final_south_br_census_oa_df.copy()\n",
    "industry_details = {'scat_category' : br_census_df['scat_category'].unique().tolist(),\n",
    " 'scat_sub_category' : br_census_df['scat_sub_category'].unique().tolist()}\n",
    "\n",
    "oas = br_census_df['oa21cd'].unique().tolist()\n",
    "years = br_census_df['year'].unique().tolist()\n",
    "south_oa_final_df = []\n",
    "\n",
    "for oa in oas:\n",
    "    print(f\"Processing oa {oa} with time is {str(datetime.datetime.now())}\")\n",
    "    oa_m2 = br_census_df[br_census_df['oa21cd'] == oa]['area_m2'].iloc[0]\n",
    "    oa_ladnm = br_census_df[br_census_df['oa21cd'] == oa]['ladnm'].iloc[0]\n",
    "    oa_plat2023 = br_census_df[br_census_df['oa21cd'] == oa]['PTAL2023_main'].iloc[0]\n",
    "    oa_prox = br_census_df[br_census_df['oa21cd'] == oa]['prox_class'].iloc[0]\n",
    "    oa_lat = br_census_df[br_census_df['oa21cd'] == oa]['oa_lat'].iloc[0]\n",
    "    oa_long = br_census_df[br_census_df['oa21cd'] == oa]['oa_long'].iloc[0]\n",
    "    for year in years:\n",
    "        tmp = br_census_df[(br_census_df['oa21cd'] == oa) & (br_census_df['year'] == year)].copy()\n",
    "        census_total = len(tmp[tmp['source'] == 'Census'])\n",
    "        census_total = census_total if census_total else np.nan\n",
    "        br_total = len(tmp[tmp['source'] == 'BR'])\n",
    "        br_total = br_total if br_total else np.nan\n",
    "        both_total = len(tmp[tmp['source'] == 'Both'])\n",
    "        both_total = both_total if both_total else np.nan\n",
    "        total = len(tmp)\n",
    "        survival_count = len(tmp[(tmp['survived'])])\n",
    "        survival_rate = survival_count / total if total else 0\n",
    "        new_count = len(tmp[(tmp['new_business'])]) \n",
    "        new_rate = new_count / total if total else 0\n",
    "        moved_count = len(tmp[(tmp['moved'])])\n",
    "        moved_rate = moved_count / total if total else 0\n",
    "        moved_within_count = len(tmp[(tmp['moved']) & (tmp['moved_within'])])\n",
    "        moved_within_rate = moved_within_count / total if total else 0\n",
    "        moved_outside_count = len(tmp[(tmp['moved']) & (~tmp['moved_within'])])\n",
    "        moved_outside_rate = moved_outside_count / total if total else 0\n",
    "        PTAL_moved_closer_count = len(tmp[(tmp['PTAL_moved_closer'])])\n",
    "        PTAL_moved_closer_rate = PTAL_moved_closer_count / total if total else 0\n",
    "        PTAL_moved_further_count = len(tmp[(tmp['PTAL_moved_further'])])\n",
    "        PTAL_moved_further_rate = PTAL_moved_further_count / total if total else 0\n",
    "        PTAL_moved_same_count = len(tmp[(tmp['PTAL_moved_same'])])\n",
    "        PTAL_moved_same_rate = PTAL_moved_same_count / total if total else 0\n",
    "        prox_moved_closer_count = len(tmp[(tmp['prox_moved_closer'])])\n",
    "        prox_moved_closer_rate = prox_moved_closer_count / total if total else 0\n",
    "        prox_moved_further_count = len(tmp[(tmp['prox_moved_further'])])\n",
    "        prox_moved_further_rate = prox_moved_further_count / total if total else 0\n",
    "        prox_moved_same_count = len(tmp[(tmp['prox_moved_same'])])\n",
    "        prox_moved_same_rate = prox_moved_same_count / total if total else 0\n",
    "        dissolved_count = len(tmp[(tmp['dissolved_business'])])\n",
    "        dissolved_rate = dissolved_count / total if total else 0\n",
    "        rates_expected_mean = tmp['rates_expected'].mean()\n",
    "        rental_valuation_mean = tmp['rental_valuation'].mean()\n",
    "        floor_area_mean = tmp['floor_area'].mean()\n",
    "        rates_expected_per_area_mean = tmp['rates_expected_per_area'].mean()\n",
    "        rental_valuation_per_area_mean = tmp['rental_valuation_per_area'].mean()\n",
    "        rates_expected_std = tmp['rates_expected'].std()\n",
    "        rental_valuation_std = tmp['rental_valuation'].std()\n",
    "        floor_area_std = tmp['floor_area'].std()\n",
    "        \n",
    "        oa_dic = {'oa21cd' : [oa], 'year' : [year], 'area_m2' : [oa_m2], 'oa_ladnm' : [oa_ladnm],\n",
    "      'oa_plat2023' : [oa_plat2023], 'oa_prox' : [oa_prox],\n",
    "      'oa_lat' : [oa_lat], 'oa_long' : [oa_long], 'bus_count_actual' : [total],\n",
    "      'census_bus_count' : [census_total], 'br_bus_count' : [br_total], 'both_bus_count' : [both_total],\n",
    "      'survival_rate' : [survival_rate], 'new_rate' : [new_rate], 'moved_rate' : [moved_rate],\n",
    "      'moved_within_rate' : [moved_within_rate],  'moved_outside_rate' : [moved_outside_rate],\n",
    "      'dissolved_rate' : [dissolved_rate], 'PTAL_moved_closer_rate' : [PTAL_moved_closer_rate],\n",
    "      'PTAL_moved_further_rate' : [PTAL_moved_further_rate], 'PTAL_moved_same_rate' : [PTAL_moved_same_rate],\n",
    "      'prox_moved_closer_rate' : [prox_moved_closer_rate],\n",
    "      'prox_moved_further_rate' : [prox_moved_further_rate], 'prox_moved_same_rate' : [prox_moved_same_rate],\n",
    "      'survival_count' : [survival_count], 'new_count' : [new_count],\n",
    "      'moved_count' : [moved_count], 'moved_within_count' : [moved_within_count],  'moved_outside_count' : [moved_outside_count],\n",
    "      'dissolved_count' : [dissolved_count], 'PTAL_moved_closer_count' : [PTAL_moved_closer_count],\n",
    "      'PTAL_moved_further_count' : [PTAL_moved_further_count], 'PTAL_moved_same_count' : [PTAL_moved_same_count],\n",
    "      'prox_moved_closer_count' : [prox_moved_closer_count],\n",
    "      'prox_moved_further_count' : [prox_moved_further_count], 'prox_moved_same_count' : [prox_moved_same_count],\n",
    "      'rates_expected_mean' : [rates_expected_mean],\n",
    "      'rental_valuation_mean' : [rental_valuation_mean], 'floor_area_mean' : [floor_area_mean],\n",
    "      'rates_expected_per_area_mean' : [rates_expected_per_area_mean], 'rental_valuation_per_area_mean' : [rental_valuation_per_area_mean],\n",
    "      'rates_expected_std' : [rates_expected_std], 'rental_valuation_std' : [rental_valuation_std],\n",
    "      'floor_area_std' : [floor_area_std], 'industry' : ['All']\n",
    "              }\n",
    "        south_oa_final_df.append(pd.DataFrame(oa_dic))\n",
    "        for industry_col in industry_details:\n",
    "            for industry in industry_details[industry_col]:\n",
    "                tmp = br_census_df[(br_census_df['oa21cd'] == oa) &\n",
    "                                         (br_census_df['year'] == year) &\n",
    "                                         (br_census_df[industry_col] == industry)].copy()\n",
    "                census_total = len(tmp[tmp['source'] == 'Census'])\n",
    "                census_total = census_total if total else np.nan\n",
    "                br_total = len(tmp[tmp['source'] == 'BR'])\n",
    "                br_total = br_total if total else np.nan\n",
    "                both_total = len(tmp[tmp['source'] == 'Both'])\n",
    "                both_total = both_total if total else np.nan\n",
    "                indus_total = len(tmp)\n",
    "                survival_count = len(tmp[(tmp['survived'])])\n",
    "                survival_rate = survival_count / indus_total if indus_total else 0\n",
    "                new_count = len(tmp[(tmp['new_business'])]) \n",
    "                new_rate = new_count / indus_total if indus_total else 0\n",
    "                moved_count = len(tmp[(tmp['moved'])])\n",
    "                moved_within_count = len(tmp[(tmp['moved']) & (tmp['moved_within'])])\n",
    "                moved_within_rate = moved_within_count / indus_total if indus_total else 0\n",
    "                moved_outside_count = len(tmp[(tmp['moved']) & (~tmp['moved_within'])])\n",
    "                moved_outside_rate = moved_outside_count / indus_total if indus_total else 0\n",
    "                moved_rate = moved_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_closer_count = len(tmp[(tmp['PTAL_moved_closer'])])\n",
    "                PTAL_moved_closer_rate = PTAL_moved_closer_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_further_count = len(tmp[(tmp['PTAL_moved_further'])])\n",
    "                PTAL_moved_further_rate = PTAL_moved_further_count / indus_total if indus_total else 0\n",
    "                PTAL_moved_same_count = len(tmp[(tmp['PTAL_moved_same'])])\n",
    "                PTAL_moved_same_rate = PTAL_moved_same_count / indus_total if indus_total else 0\n",
    "                prox_moved_closer_count = len(tmp[(tmp['prox_moved_closer'])])\n",
    "                prox_moved_closer_rate = prox_moved_closer_count / indus_total if indus_total else 0\n",
    "                prox_moved_further_count = len(tmp[(tmp['prox_moved_further'])])\n",
    "                prox_moved_further_rate = prox_moved_further_count / indus_total if indus_total else 0\n",
    "                prox_moved_same_count = len(tmp[(tmp['prox_moved_same'])])\n",
    "                prox_moved_same_rate = prox_moved_same_count / indus_total if indus_total else 0\n",
    "                dissolved_count = len(tmp[(tmp['dissolved_business'])])\n",
    "                dissolved_rate = dissolved_count / indus_total if indus_total else 0\n",
    "                rates_expected_mean = tmp['rates_expected'].mean()\n",
    "                rental_valuation_mean = tmp['rental_valuation'].mean()\n",
    "                floor_area_mean = tmp['floor_area'].mean()\n",
    "                rates_expected_per_area_mean = tmp['rates_expected_per_area'].mean()\n",
    "                rental_valuation_per_area_mean = tmp['rental_valuation_per_area'].mean()\n",
    "                rates_expected_std = tmp['rates_expected'].std()\n",
    "                rental_valuation_std = tmp['rental_valuation'].std()\n",
    "                floor_area_std = tmp['floor_area'].std()\n",
    "                \n",
    "                oa_dic = {'oa21cd' : [oa], 'year' : [year], 'area_m2' : [oa_m2], 'oa_ladnm' : [oa_ladnm],\n",
    "      'oa_plat2023' : [oa_plat2023], 'oa_prox' : [oa_prox],\n",
    "      'oa_lat' : [oa_lat], 'oa_long' : [oa_long], 'bus_count_actual' : [indus_total],\n",
    "      'census_bus_count' : [census_total], 'br_bus_count' : [br_total], 'both_bus_count' : [both_total],\n",
    "      'survival_rate' : [survival_rate], 'new_rate' : [new_rate], 'moved_rate' : [moved_rate],\n",
    "      'moved_within_rate' : [moved_within_rate],  'moved_outside_rate' : [moved_outside_rate],\n",
    "      'dissolved_rate' : [dissolved_rate], 'PTAL_moved_closer_rate' : [PTAL_moved_closer_rate],\n",
    "      'PTAL_moved_further_rate' : [PTAL_moved_further_rate], 'PTAL_moved_same_rate' : [PTAL_moved_same_rate],\n",
    "      'prox_moved_closer_rate' : [prox_moved_closer_rate],\n",
    "      'prox_moved_further_rate' : [prox_moved_further_rate], 'prox_moved_same_rate' : [prox_moved_same_rate],\n",
    "      'survival_count' : [survival_count], 'new_count' : [new_count],\n",
    "      'moved_count' : [moved_count], 'moved_within_count' : [moved_within_count],  'moved_outside_count' : [moved_outside_count],\n",
    "      'dissolved_count' : [dissolved_count], 'PTAL_moved_closer_count' : [PTAL_moved_closer_count],\n",
    "      'PTAL_moved_further_count' : [PTAL_moved_further_count], 'PTAL_moved_same_count' : [PTAL_moved_same_count],\n",
    "      'prox_moved_closer_count' : [prox_moved_closer_count],\n",
    "      'prox_moved_further_count' : [prox_moved_further_count], 'prox_moved_same_count' : [prox_moved_same_count],\n",
    "      'rates_expected_mean' : [rates_expected_mean],\n",
    "      'rental_valuation_mean' : [rental_valuation_mean], 'floor_area_mean' : [floor_area_mean],\n",
    "      'rates_expected_per_area_mean' : [rates_expected_per_area_mean], 'rental_valuation_per_area_mean' : [rental_valuation_per_area_mean],\n",
    "      'rates_expected_std' : [rates_expected_std], 'rental_valuation_std' : [rental_valuation_std],\n",
    "      'floor_area_std' : [floor_area_std], 'industry' : [industry]\n",
    "              }\n",
    "                south_oa_final_df.append(pd.DataFrame(oa_dic))\n",
    "group_cols = ['oa21cd', 'industry']\n",
    "south_oa_final_df = pd.concat(south_oa_final_df, ignore_index = True).sort_values(by = ['oa21cd', 'year'])\n",
    "south_oa_final_df['census_bus_count'] = south_oa_final_df.groupby(group_cols)['census_bus_count'].bfill().fillna(0)\n",
    "south_oa_final_df['br_bus_count'] = south_oa_final_df['br_bus_count'].fillna(0)\n",
    "#south_oa_final_df['both_bus_count'] = south_oa_final_df.groupby(group_cols)['both_bus_count'].bfill()\n",
    "south_oa_final_df['bus_count'] = south_oa_final_df['census_bus_count'] + south_oa_final_df['br_bus_count'] \\\n",
    "                                + south_oa_final_df['both_bus_count']\n",
    "south_oa_final_df.to_pickle(\"Old_Kent_oa_final_df_v5.pkl\")\n",
    "south_oa_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5498ac-8db6-4b7a-87c7-323d3dd0209d",
   "metadata": {},
   "source": [
    "# Prepare other Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6eb4c-daa6-46df-a74f-f7fc591f7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lsoa_mapping_df = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\PCD_OA21_LSOA21.csv\",\n",
    "                                 encoding = \"ISO-8859-1\")\n",
    "pc_lsoa_mapping_df = pc_lsoa_mapping_df[(pc_lsoa_mapping_df['ladnm'] == 'Wandsworth') |\n",
    "            (pc_lsoa_mapping_df['ladnm'] == 'Southwark') | (pc_lsoa_mapping_df['ladnm'] == 'Lambeth')].copy()\n",
    "lsoa11_to_lsoa21 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\LSOA_(2011)_to_LSOA_(2021).csv\")\n",
    "lsoa01_to_lsoa11 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\LSOA_(2001)_to_LSOA_(2011).csv\")\n",
    "\n",
    "lsoa_cols = ['lsoa11cd', 'lsoa21cd']\n",
    "lsoa01_cols = ['lsoa01cd', 'lsoa11cd']\n",
    "\n",
    "lsoa21 = pc_lsoa_mapping_df[pc_lsoa_mapping_df['oa21cd'].isin(oa_final_df['oa21cd'].unique())\n",
    "        ][['oa21cd', 'lsoa21cd']].drop_duplicates()\n",
    "south_lsoa21 = pc_lsoa_mapping_df[pc_lsoa_mapping_df['oa21cd'].isin(south_oa_final_df['oa21cd'].unique())\n",
    "        ][['oa21cd', 'lsoa21cd']].drop_duplicates()\n",
    "\n",
    "lsoa11_to_lsoa21.columns = [c.lower() for c in lsoa11_to_lsoa21.columns]\n",
    "lsoa01_to_lsoa11.columns = [c.lower() for c in lsoa01_to_lsoa11.columns]\n",
    "\n",
    "lsoa11_to_lsoa21_map = lsoa21.set_index('lsoa21cd').join(lsoa11_to_lsoa21[lsoa_cols].set_index('lsoa21cd')).reset_index()\n",
    "lsoa01_to_lsoa21_map = lsoa21.set_index('lsoa21cd').join(lsoa11_to_lsoa21[lsoa_cols].set_index('lsoa21cd')\n",
    "                ).reset_index().set_index('lsoa11cd').join(lsoa01_to_lsoa11[lsoa01_cols].set_index('lsoa11cd')).reset_index()\n",
    "\n",
    "south_lsoa11_to_lsoa21_map = south_lsoa21.set_index('lsoa21cd').join(\n",
    "                    lsoa11_to_lsoa21[lsoa_cols].set_index('lsoa21cd')).reset_index()\n",
    "south_lsoa01_to_lsoa21_map = south_lsoa21.set_index('lsoa21cd').join(lsoa11_to_lsoa21[lsoa_cols].set_index('lsoa21cd')\n",
    "                ).reset_index().set_index('lsoa11cd').join(lsoa01_to_lsoa11[lsoa01_cols].set_index('lsoa11cd')).reset_index()\n",
    "\n",
    "print(lsoa11_to_lsoa21_map.shape)\n",
    "print(south_lsoa11_to_lsoa21_map.shape)\n",
    "\n",
    "print(lsoa01_to_lsoa21_map.shape)\n",
    "print(south_lsoa01_to_lsoa21_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be682a-aaba-4494-b0fb-7e8624cd8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data\\\\MEP CDRC\\\\MEP_LSOA\\\\MEP_LSOA\\\\'\n",
    "mep_full_df = []\n",
    "for f in range(14):\n",
    "    year = 2010 + f\n",
    "    filename = f\"MEP_lsoa11_{year}.csv\"\n",
    "    df = pd.read_csv(path + filename)\n",
    "    df['year']= year\n",
    "    mep_full_df.append(df)\n",
    "mep_full_df = pd.concat(mep_full_df, ignore_index=True)\n",
    "mep_full_df = mep_full_df.rename(columns = {'lsoa11' : 'lsoa11cd'})\n",
    "mep_full_df.columns = ['lsoa11cd'] + [c + '_lsoa' for c in mep_full_df.columns[1:-1]] + ['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a987f-e708-481a-8e56-5148d592ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mep_full_df = lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(mep_full_df.set_index('lsoa11cd')\n",
    "                                                             ).reset_index()\n",
    "filtered_south_mep_full_df = south_lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    mep_full_df.set_index('lsoa11cd')).reset_index()\n",
    "\n",
    "print(filtered_mep_full_df.shape)\n",
    "print(filtered_south_mep_full_df.shape)\n",
    "filtered_mep_full_df = filtered_mep_full_df.sort_values(by = ['year', 'lsoa11cd'])\n",
    "filtered_south_mep_full_df = filtered_south_mep_full_df.sort_values(by = ['year', 'lsoa11cd'])\n",
    "\n",
    "filtered_mep_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437330ae-7f85-4cfd-a1cf-ebd7417a8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "oa11_to_oa21 = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\OA_(2011)_to_OA_(2021).csv\")\n",
    "oa11_to_oa21.columns = [c.lower() for c in oa11_to_oa21.columns]\n",
    "oa11_to_oa21_map = oa11_to_oa21[oa11_to_oa21['oa21cd'].isin(oa_final_df['oa21cd'].unique())][['oa11cd', 'oa21cd']]\n",
    "south_oa11_to_oa21_map = oa11_to_oa21[oa11_to_oa21['oa21cd'].isin(\n",
    "                    south_oa_final_df['oa21cd'].unique())][['oa11cd', 'oa21cd']]\n",
    "print(len(oa11_to_oa21_map))\n",
    "print(len(south_oa11_to_oa21_map))\n",
    "oa11_to_oa21_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c359c3-9a7a-476c-89a2-133be607ae90",
   "metadata": {},
   "source": [
    "# Generate OA Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf033416-7618-40aa-954f-cdddc336c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pop_oa_df = []\n",
    "final_south_pop_oa_df = []\n",
    "for i in range(2):\n",
    "    year = 2010 + i\n",
    "    pop_oa_df = pd.read_excel(f\"Data\\\\OA Population\\\\sapemid2011.xls\", sheet_name = f'london_{year}')\n",
    "    pop_oa_df = pop_oa_df.rename(columns = {'All Ages' : 'total_pop'})\n",
    "    pop_oa_df['pop_19_64'] = pop_oa_df[[i for i in range(19,65)]].sum(axis = 1)\n",
    "    pop_oa_df = pop_oa_df.groupby(['OA11CD', 'LAD11CD']).sum()[['total_pop', 'pop_19_64']].reset_index()\n",
    "    pop_oa_df = pop_oa_df[['OA11CD', 'LAD11CD', 'total_pop', 'pop_19_64']]\n",
    "    pop_oa_df.columns = [c.lower() for c in pop_oa_df.columns]\n",
    "    \n",
    "    south_pop_oa_df = south_oa11_to_oa21_map.set_index('oa11cd').join(pop_oa_df.set_index('oa11cd')).reset_index()\n",
    "    south_pop_oa_df = south_pop_oa_df.set_index('oa11cd').join(south_pop_oa_df.groupby('oa11cd').count()[\n",
    "                   ['oa21cd']].rename(columns = {'oa21cd' : 'oa21cd_count'})).reset_index().rename(columns = \n",
    "                                      {'total_pop' : 'total_pop_oa11cd', 'pop_19_64' : 'pop_19_64_oa11cd'})\n",
    "    south_pop_oa_df['total_pop'] = (south_pop_oa_df['total_pop_oa11cd'] / south_pop_oa_df['oa21cd_count']).apply(\n",
    "        np.round)\n",
    "    south_pop_oa_df['pop_19_64'] = (south_pop_oa_df['pop_19_64_oa11cd'] / south_pop_oa_df['oa21cd_count']).apply(\n",
    "        np.round)\n",
    "    south_pop_oa_df = south_pop_oa_df[['oa21cd', 'total_pop', 'pop_19_64']].groupby('oa21cd').sum().reset_index()\n",
    "    south_pop_oa_df['year'] = year\n",
    "    \n",
    "    pop_oa_df = oa11_to_oa21_map.set_index('oa11cd').join(pop_oa_df.set_index('oa11cd')).reset_index()\n",
    "    pop_oa_df = pop_oa_df.set_index('oa11cd').join(pop_oa_df.groupby('oa11cd').count()[\n",
    "                   ['oa21cd']].rename(columns = {'oa21cd' : 'oa21cd_count'})).reset_index().rename(columns = \n",
    "                                      {'total_pop' : 'total_pop_oa11cd', 'pop_19_64' : 'pop_19_64_oa11cd'})\n",
    "    pop_oa_df['total_pop'] = (pop_oa_df['total_pop_oa11cd'] / pop_oa_df['oa21cd_count']).apply(np.round)\n",
    "    pop_oa_df['pop_19_64'] = (pop_oa_df['pop_19_64_oa11cd'] / pop_oa_df['oa21cd_count']).apply(np.round)\n",
    "    pop_oa_df = pop_oa_df[['oa21cd', 'total_pop', 'pop_19_64']].groupby('oa21cd').sum().reset_index()\n",
    "    pop_oa_df['year'] = year\n",
    "    final_pop_oa_df.append(pop_oa_df)\n",
    "    final_south_pop_oa_df.append(south_pop_oa_df)\n",
    "\n",
    "for i in range(9):\n",
    "    year = 2012 + i\n",
    "    pop_oa_df = pd.read_excel(f\"Data\\\\OA Population\\\\sapemid{year}.xlsx\",\n",
    "                             sheet_name = f'Mid-{year} Persons', skiprows = 4)\n",
    "    pop_oa_df = pop_oa_df.rename(columns = {'All Ages' : 'total_pop'})\n",
    "    pop_oa_df['pop_19_64'] = pop_oa_df[[i for i in range(19,65)]].sum(axis = 1)\n",
    "    pop_oa_df = pop_oa_df[['OA11CD', 'LSOA11CD', 'total_pop', 'pop_19_64']]\n",
    "    pop_oa_df.columns = [c.lower() for c in pop_oa_df.columns]\n",
    "    \n",
    "    south_pop_oa_df = south_oa11_to_oa21_map.set_index('oa11cd').join(pop_oa_df.set_index('oa11cd')).reset_index()\n",
    "    south_pop_oa_df = south_pop_oa_df.set_index('oa11cd').join(south_pop_oa_df.groupby('oa11cd').count()[\n",
    "                   ['oa21cd']].rename(columns = {'oa21cd' : 'oa21cd_count'})).reset_index().rename(columns = \n",
    "                                      {'total_pop' : 'total_pop_oa11cd', 'pop_19_64' : 'pop_19_64_oa11cd'})\n",
    "    south_pop_oa_df['total_pop'] = (south_pop_oa_df['total_pop_oa11cd'] / south_pop_oa_df['oa21cd_count']).apply(\n",
    "        np.round)\n",
    "    south_pop_oa_df['pop_19_64'] = (south_pop_oa_df['pop_19_64_oa11cd'] / south_pop_oa_df['oa21cd_count']).apply(\n",
    "        np.round)\n",
    "    south_pop_oa_df = south_pop_oa_df[['oa21cd', 'total_pop', 'pop_19_64']].groupby('oa21cd').sum().reset_index()\n",
    "    south_pop_oa_df['year'] = year\n",
    "    \n",
    "    pop_oa_df = oa11_to_oa21_map.set_index('oa11cd').join(pop_oa_df.set_index('oa11cd')).reset_index()\n",
    "    pop_oa_df = pop_oa_df.set_index('oa11cd').join(pop_oa_df.groupby('oa11cd').count()[\n",
    "                   ['oa21cd']].rename(columns = {'oa21cd' : 'oa21cd_count'})).reset_index().rename(columns = \n",
    "                                      {'total_pop' : 'total_pop_oa11cd', 'pop_19_64' : 'pop_19_64_oa11cd'})\n",
    "    pop_oa_df['total_pop'] = (pop_oa_df['total_pop_oa11cd'] / pop_oa_df['oa21cd_count']).apply(np.round)\n",
    "    pop_oa_df['pop_19_64'] = (pop_oa_df['pop_19_64_oa11cd'] / pop_oa_df['oa21cd_count']).apply(np.round)\n",
    "    pop_oa_df = pop_oa_df[['oa21cd', 'total_pop', 'pop_19_64']].groupby('oa21cd').sum().reset_index()\n",
    "    pop_oa_df['year'] = year\n",
    "    final_pop_oa_df.append(pop_oa_df)\n",
    "    final_south_pop_oa_df.append(south_pop_oa_df)\n",
    "\n",
    "for i in range(2):\n",
    "    year = 2021 + i\n",
    "    pop_oa_df = pd.read_excel(f\"Data\\\\OA Population\\\\sapeoatablefinal{year}v2.xlsx\",\n",
    "                             sheet_name = f'Mid-{year} OA 2021', skiprows = 3)\n",
    "    pop_oa_df = pop_oa_df.rename(columns = {'Total' : 'total_pop', 'OA 2021 Code' : 'oa21cd', 'LAD 2021 Code' : \n",
    "                                           'lsoa11cd'})\n",
    "    pop_oa_df['female_pop_19_64'] = pop_oa_df[[f'F{i}' for i in range(19,65)]].sum(axis = 1)\n",
    "    pop_oa_df['male_pop_19_64'] = pop_oa_df[[f'M{i}' for i in range(19,65)]].sum(axis = 1)\n",
    "    pop_oa_df['pop_19_64'] = pop_oa_df['male_pop_19_64'] + pop_oa_df['female_pop_19_64']\n",
    "    pop_oa_df['year'] = year\n",
    "    pop_oa_df = pop_oa_df[['oa21cd','total_pop','pop_19_64','year']]\n",
    "    south_pop_oa_df = pop_oa_df[pop_oa_df['oa21cd'].isin(south_oa11_to_oa21_map['oa21cd'].unique())]\n",
    "    pop_oa_df = pop_oa_df[pop_oa_df['oa21cd'].isin(oa11_to_oa21_map['oa21cd'].unique())]\n",
    "    final_pop_oa_df.append(pop_oa_df)\n",
    "    final_south_pop_oa_df.append(south_pop_oa_df)\n",
    "\n",
    "pop_oa_df['year'] = 2023\n",
    "south_pop_oa_df['year'] = 2023\n",
    "final_pop_oa_df.append(pop_oa_df)\n",
    "final_south_pop_oa_df.append(south_pop_oa_df)\n",
    "pop_oa_df['year'] = 2024\n",
    "south_pop_oa_df['year'] = 2024\n",
    "final_pop_oa_df.append(pop_oa_df)\n",
    "final_south_pop_oa_df.append(south_pop_oa_df)\n",
    "\n",
    "final_pop_oa_df = pd.concat(final_pop_oa_df, ignore_index = True)\n",
    "final_south_pop_oa_df = pd.concat(final_south_pop_oa_df, ignore_index = True)\n",
    "final_pop_oa_df.to_pickle(\"final_pop_oa_df.pkl\")\n",
    "final_south_pop_oa_df.to_pickle(\"final_south_pop_oa_df.pkl\")\n",
    "final_pop_oa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6310f13-6e0c-4667-bf73-badb15009b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pop_oa_df = pd.read_pickle(\"final_pop_oa_df.pkl\")\n",
    "final_south_pop_oa_df = pd.read_pickle(\"final_south_pop_oa_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e477e7-541b-4f45-b26d-d2ae6061dd20",
   "metadata": {},
   "source": [
    "# Load House Occupants Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481e872-01b9-4d83-beae-beb8c54636f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process dataset\n",
    "hh_churn_df_test = pd.read_csv('Data\\\\CDRC Residential Mobility Index\\\\hh_churn_lsoa11_2023.csv')\n",
    "hh_churn_df_test = hh_churn_df_test.rename(columns = {'area' : 'lsoa11cd'})\n",
    "\n",
    "south_hh_churn_df_test = south_lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    hh_churn_df_test.set_index('lsoa11cd')).reset_index()\n",
    "hh_churn_df_test = lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(hh_churn_df_test.set_index('lsoa11cd')\n",
    "                                                             ).reset_index()\n",
    "\n",
    "hh_churn_df = []\n",
    "south_hh_churn_df = []\n",
    "for i in range(13):\n",
    "    year = 2010 + i\n",
    "    tmp = hh_churn_df_test[['lsoa11cd', 'lsoa21cd','oa21cd', f'chn{year}']].rename(columns =\n",
    "                                                           {f'chn{year}' : 'hh_chn'}).copy()\n",
    "    tmp['year'] = year\n",
    "    hh_churn_df.append(tmp)\n",
    "    tmp = south_hh_churn_df_test[['lsoa11cd', 'lsoa21cd','oa21cd', f'chn{year}']].rename(columns = \n",
    "                                                         {f'chn{year}' : 'hh_chn'}).copy()\n",
    "    tmp['year'] = year\n",
    "    south_hh_churn_df.append(tmp)\n",
    "\n",
    "hh_churn_df = pd.concat(hh_churn_df, ignore_index = True)\n",
    "south_hh_churn_df = pd.concat(south_hh_churn_df, ignore_index = True)\n",
    "hh_churn_df.to_pickle(\"hh_churn_df.pkl\")\n",
    "south_hh_churn_df.to_pickle(\"south_hh_churn_df.pkl\")\n",
    "hh_churn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49bb60-7aaa-421d-a0f2-c7acf0fc75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pop_oa_df = pd.read_pickle(\"final_pop_oa_df.pkl\")\n",
    "final_south_pop_oa_df = pd.read_pickle(\"final_south_pop_oa_df.pkl\")\n",
    "hh_churn_df = pd.read_pickle(\"hh_churn_df.pkl\")\n",
    "south_hh_churn_df = pd.read_pickle(\"south_hh_churn_df.pkl\")\n",
    "final_pop_oa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1857ef-ff29-4c7a-bf59-9f29bf3e47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_lsoa_mapping_df = pd.read_csv(\"Data\\\\PCD_OA21_LSOA21\\\\PCD_OA21_LSOA21.csv\",\n",
    "                                 encoding = \"ISO-8859-1\")\n",
    "pc_lsoa_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb72df-3348-4c0c-b3f1-8c783e4ec71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cols = ['priceper', 'year', 'postcode', 'oa_ladnm']\n",
    "tmp = pd.read_csv('Data\\\\House Prices\\\\Lambeth_link_26122024.csv')\n",
    "tmp['oa_ladnm'] = 'Lambeth'\n",
    "tmp1 = pd.read_csv('Data\\\\House Prices\\\\Wandsworth_link_26122024.csv')\n",
    "tmp1['oa_ladnm'] = 'Wandsworth'\n",
    "prop_prices_df = pd.concat([tmp[prop_cols], tmp1[prop_cols]], ignore_index = True)\n",
    "print(prop_prices_df.shape)\n",
    "prop_prices_df = prop_prices_df.set_index('postcode').join(pc_lsoa_mapping_df.rename(columns =\n",
    "                 {'pcds' : 'postcode'}).set_index('postcode')[['oa21cd']].drop_duplicates(), how = 'inner'\n",
    "                 ).reset_index()\n",
    "prop_prices_df = prop_prices_df[prop_prices_df['year'] >= 2010].copy()\n",
    "prop_prices_df = prop_prices_df[['oa21cd', 'oa_ladnm', 'year', 'priceper']].groupby(\n",
    "    ['oa21cd', 'oa_ladnm', 'year']).mean().reset_index()\n",
    "prop_prices_df = prop_prices_df.sort_values(by = ['year', 'oa21cd'])\n",
    "prop_prices_df = lsoa21.set_index('oa21cd').join(prop_prices_df.set_index('oa21cd')).reset_index()\n",
    "print(len(prop_prices_df['oa21cd'].unique()))\n",
    "print(prop_prices_df.shape)\n",
    "for year in prop_prices_df['year'].unique():\n",
    "    for oa in lsoa21['oa21cd'].unique():\n",
    "        if not len(prop_prices_df[(prop_prices_df['year'] == year) & (prop_prices_df['oa21cd'] == oa)]):\n",
    "            m = prop_prices_df[(prop_prices_df['year'] == year)]['priceper'].mean()\n",
    "            lsoa = lsoa21[lsoa21['oa21cd'] == oa].iloc[0]['lsoa21cd']\n",
    "            ladnm = oa_final_df[oa_final_df['oa21cd'] == oa].iloc[0]['oa_ladnm']\n",
    "            prop_prices_df = pd.concat([prop_prices_df, pd.DataFrame({'oa21cd' : [oa],\n",
    "        'oa_ladnm' : [ladnm], 'year' : [year], 'priceper' : [m], 'lsoa21cd' : [lsoa]})], ignore_index = True)\n",
    "print(prop_prices_df.shape)\n",
    "print(prop_prices_df[prop_prices_df['oa21cd'].apply(pd.isna)].shape)\n",
    "south_prop_prices_df = pd.read_csv('Data\\\\House Prices\\\\Southwark_link_26122024.csv')\n",
    "south_prop_prices_df['oa_ladnm'] = 'Southwark'\n",
    "south_prop_prices_df = south_prop_prices_df[prop_cols].copy()\n",
    "print(south_prop_prices_df.shape)\n",
    "south_prop_prices_df = south_prop_prices_df.set_index('postcode').join(pc_lsoa_mapping_df.rename(columns =\n",
    "                 {'pcds' : 'postcode'}).set_index('postcode')[['oa21cd']].drop_duplicates(), how = 'inner'\n",
    "              ).reset_index()\n",
    "south_prop_prices_df = south_prop_prices_df[south_prop_prices_df['year'] >= 2010].copy()\n",
    "south_prop_prices_df = south_prop_prices_df[['oa21cd', 'oa_ladnm', 'year', 'priceper']].groupby(\n",
    "    ['oa21cd', 'oa_ladnm', 'year']).mean().reset_index()\n",
    "south_prop_prices_df = south_prop_prices_df.sort_values(by = ['year', 'oa21cd'])\n",
    "south_prop_prices_df = south_lsoa21.set_index('oa21cd').join(south_prop_prices_df.set_index('oa21cd')\n",
    "                                                            ).reset_index()\n",
    "for year in south_prop_prices_df['year'].unique():\n",
    "    for oa in south_lsoa21['oa21cd'].unique():\n",
    "        if not len(south_prop_prices_df[(south_prop_prices_df['year'] == year) &\n",
    "                   (south_prop_prices_df['oa21cd'] == oa)]):\n",
    "            m = south_prop_prices_df[(south_prop_prices_df['year'] == year)]['priceper'].mean()\n",
    "            lsoa = south_lsoa21[south_lsoa21['oa21cd'] == oa].iloc[0]['lsoa21cd']\n",
    "            ladnm = south_oa_final_df[south_oa_final_df['oa21cd'] == oa].iloc[0]['oa_ladnm']\n",
    "            south_prop_prices_df = pd.concat([south_prop_prices_df, pd.DataFrame({'oa21cd' : [oa],\n",
    "        'oa_ladnm' : [ladnm], 'year' : [year], 'priceper' : [m], 'lsoa21cd' : [lsoa]})], ignore_index = True)\n",
    "print(len(south_prop_prices_df['oa21cd'].unique()))\n",
    "print(south_prop_prices_df.shape)\n",
    "\n",
    "prop_prices_df = prop_prices_df[~prop_prices_df['year'].apply(pd.isna)].sort_values(by = ['year', 'oa21cd'])\n",
    "south_prop_prices_df = south_prop_prices_df[~south_prop_prices_df['year'].apply(pd.isna)\n",
    "].sort_values(by = ['year', 'oa21cd'])\n",
    "prop_prices_df.to_pickle(\"prop_prices_df.pkl\")\n",
    "south_prop_prices_df.to_pickle(\"south_prop_prices_df.pkl\")\n",
    "\n",
    "prop_prices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53548a-6eeb-4c0a-a5ef-18bf60c98e8e",
   "metadata": {},
   "source": [
    "# Process RMD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ebe6d-db55-446a-865f-9b80b9222b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmd_in_df = pd.read_csv(\"Data\\\\RMD CDRC\\\\RMD_LSOA_1997_2023\\\\RMD_in_LSOA.csv\")\n",
    "rmd_in_df = rmd_in_df.rename(columns = {'d_first' : 'year', 'd_lsoa11' : 'lsoa11cd',\n",
    "            'mean_imd_change' : 'imd_change_in', 'count' : 'in_count'})\n",
    "rmd_in_df = rmd_in_df[rmd_in_df['year'] >= 2010].copy()\n",
    "rmd_out_df = pd.read_csv(\"Data\\\\RMD CDRC\\\\RMD_LSOA_1997_2023\\\\RMD_out_LSOA.csv\")\n",
    "rmd_out_df = rmd_out_df.rename(columns = {'o_last' : 'year', 'o_lsoa11' : 'lsoa11cd',\n",
    "            'mean_imd_change' : 'imd_change_out', 'count' : 'out_count'})\n",
    "rmd_out_df = rmd_out_df[rmd_out_df['year'] >= 2010].copy()\n",
    "rmd_df = rmd_in_df.set_index(['year', 'lsoa11cd']).join(rmd_out_df.set_index(['year', 'lsoa11cd'])).reset_index()\n",
    "\n",
    "\n",
    "filtered_rmd_df = lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    rmd_df.set_index('lsoa11cd')).reset_index()\n",
    "print(filtered_rmd_df.shape)\n",
    "filtered_south_rmd_df = south_lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    rmd_df.set_index('lsoa11cd')).reset_index()\n",
    "print(filtered_south_rmd_df.shape)\n",
    "filtered_rmd_df.to_pickle(\"filtered_rmd_df.pkl\")\n",
    "filtered_south_rmd_df.to_pickle(\"filtered_south_rmd_df.pkl\")\n",
    "filtered_south_rmd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd0fbb-4763-4b3d-8bfc-e2b723e49a7d",
   "metadata": {},
   "source": [
    "# Process Jobs Data 2015 till 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9be52-56d1-41ae-8902-dde0500b911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv(\"Data\\\\jobs data\\\\jobs_stats_clean.csv\")\n",
    "jobs_df.columns = [c.split(':')[1].strip().replace(';', ',') if ':' in c else c for c in jobs_df.columns]\n",
    "sic_scat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'scat_sic_mapping')\n",
    "jobs_df = jobs_df.rename(columns = {'Activities of households as employers,undifferentiated goods-and services-producing activities of households for own use' :\n",
    "                      'Activities of households as employers; undifferentiated goods- and services-producing activities of households for own use'})\n",
    "jobs_df['lsoa11cd'] = jobs_df['lsoa11cd'].apply(lambda x: x.split(':')[0].strip())\n",
    "jobs_df = jobs_df.sort_values(by = ['lsoa11cd', 'year'])\n",
    "\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a6bc9-16b8-40da-948e-cf045f945b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs_df = []\n",
    "for col in jobs_df.columns[1:-2]:\n",
    "    sector = sic_scat_map_df[sic_scat_map_df['sic_category'].apply(lambda x: str.lower(x).replace(';', ',')) == col.lower().replace(';', ',')].iloc[0]['scat_category']\n",
    "    sub_sector = sic_scat_map_df[sic_scat_map_df['sic_category'].apply(lambda x: str.lower(x).replace(';', ',')) == col.lower().replace(';', ',')].iloc[0]['scat_sub_category']\n",
    "    tmp = jobs_df[['lsoa11cd', 'year', col]].copy().rename(columns = {col : 'jobs_count'})\n",
    "    tmp['sub_sector'] = sub_sector\n",
    "    tmp['sector'] = sector\n",
    "    final_jobs_df.append(tmp)\n",
    "\n",
    "tmp = jobs_df[['lsoa11cd', 'year', 'total']].rename(columns = {'total' : 'jobs_count'})\n",
    "tmp['industry'] = 'All'\n",
    "tmp = tmp[['lsoa11cd', 'year', 'industry', 'jobs_count']]\n",
    "final_jobs_df = pd.concat(final_jobs_df, ignore_index = True)\n",
    "final_jobs_df = final_jobs_df.groupby(['lsoa11cd','year','sub_sector','sector']).sum().reset_index()\n",
    "final_jobs_df = pd.concat([final_jobs_df.groupby(['lsoa11cd', 'year', 'sub_sector']\n",
    "                        ).sum()[['jobs_count']].reset_index().rename(columns = {'sub_sector' : 'industry'}),\n",
    "                          final_jobs_df.groupby(['lsoa11cd', 'year', 'sector']\n",
    "                        ).sum()[['jobs_count']].reset_index().rename(columns = {'sector' : 'industry'}),\n",
    "                          tmp])\n",
    "print(final_jobs_df.shape)\n",
    "\n",
    "filtered_jobs_df = lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    final_jobs_df.set_index('lsoa11cd')).reset_index()\n",
    "print(filtered_jobs_df.shape)\n",
    "filtered_south_jobs_df = south_lsoa11_to_lsoa21_map.set_index('lsoa11cd').join(\n",
    "    final_jobs_df.set_index('lsoa11cd')).reset_index()\n",
    "print(filtered_south_jobs_df.shape)\n",
    "\n",
    "print(final_pop_oa_df.shape)\n",
    "final_pop_oa_df_tmp = final_pop_oa_df.set_index('oa21cd')[['year', 'total_pop']].join(\n",
    "    lsoa11_to_lsoa21_map.set_index('oa21cd')).reset_index()\n",
    "print(final_pop_oa_df_tmp.shape)\n",
    "final_pop_oa_df_tmp = final_pop_oa_df_tmp.set_index(['lsoa21cd', 'year']).join(\n",
    "    final_pop_oa_df_tmp.groupby(['lsoa21cd', 'year']).sum()[['total_pop']].rename(\n",
    "        columns = {'total_pop' : 'lsoa_total_pop'})).reset_index()\n",
    "final_pop_oa_df_tmp['total_pop_perc'] = final_pop_oa_df_tmp['total_pop'] / final_pop_oa_df_tmp['lsoa_total_pop']\n",
    "print(final_pop_oa_df_tmp.shape)\n",
    "\n",
    "print(final_south_pop_oa_df.shape)\n",
    "final_south_pop_oa_df_tmp = final_south_pop_oa_df.set_index('oa21cd')[['year', 'total_pop']].join(\n",
    "    south_lsoa11_to_lsoa21_map.set_index('oa21cd')).reset_index()\n",
    "print(final_south_pop_oa_df_tmp.shape)\n",
    "final_south_pop_oa_df_tmp = final_south_pop_oa_df_tmp.set_index(['lsoa21cd', 'year']).join(\n",
    "    final_south_pop_oa_df_tmp.groupby(['lsoa21cd', 'year']).sum()[['total_pop']].rename(\n",
    "        columns = {'total_pop' : 'lsoa_total_pop'})).reset_index()\n",
    "final_south_pop_oa_df_tmp['total_pop_perc'] = final_south_pop_oa_df_tmp['total_pop'] / final_south_pop_oa_df_tmp['lsoa_total_pop']\n",
    "print(final_south_pop_oa_df_tmp.shape)\n",
    "\n",
    "filtered_jobs_df = filtered_jobs_df.set_index(['oa21cd', 'year']\n",
    "         ).join(final_pop_oa_df_tmp.set_index(['oa21cd', 'year'])[['total_pop_perc']]).reset_index()\n",
    "filtered_jobs_df = filtered_jobs_df.rename(columns = {'jobs_count' : 'lsoa_jobs_count'})\n",
    "filtered_jobs_df['jobs_count'] = (filtered_jobs_df['lsoa_jobs_count'] * filtered_jobs_df['total_pop_perc']\n",
    "                                 ).apply(np.round)\n",
    "\n",
    "filtered_south_jobs_df = filtered_south_jobs_df.set_index(['oa21cd', 'year']\n",
    "         ).join(final_south_pop_oa_df_tmp.set_index(['oa21cd', 'year'])[['total_pop_perc']]).reset_index()\n",
    "filtered_south_jobs_df = filtered_south_jobs_df.rename(columns = {'jobs_count' : 'lsoa_jobs_count'})\n",
    "filtered_south_jobs_df['jobs_count'] = (filtered_south_jobs_df['lsoa_jobs_count'] *\n",
    "                                        filtered_south_jobs_df['total_pop_perc']).apply(np.round)\n",
    "\n",
    "filtered_jobs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae831c63-b91f-43dd-b574-01a31d9da16e",
   "metadata": {},
   "source": [
    "# Process Jobs Data 2010 till 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dc1b4-55cf-48b7-9d9d-d9257cf45849",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df_2010 = pd.read_csv(\"Data\\\\jobs data\\\\jobs_stats_clean_2010.csv\")\n",
    "jobs_df_2010.columns = [c.split(':')[1].strip().replace(';', ',') if ':' in c else c for c in jobs_df_2010.columns]\n",
    "sic_scat_map_df = pd.read_excel(\"Data/sic_cat_mapping.xlsx\", sheet_name = 'scat_sic_mapping')\n",
    "jobs_df_2010 = jobs_df_2010.rename(columns = {'Activities of households as employers,undifferentiated goods-and services-producing activities of households for own use' :\n",
    "                      'Activities of households as employers; undifferentiated goods- and services-producing activities of households for own use'})\n",
    "jobs_df_2010['lsoa01cd'] = jobs_df_2010['lsoa01cd'].apply(lambda x: x.split(':')[0].strip())\n",
    "jobs_df_2010 = jobs_df_2010.sort_values(by = ['lsoa01cd', 'year'])\n",
    "jobs_df_2010.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e798c7-1552-47a8-aebe-390a7b2dc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs_df_2010 = []\n",
    "for col in jobs_df_2010.columns[1:-2]:\n",
    "    sector = sic_scat_map_df[sic_scat_map_df['sic_category'].apply(lambda x: str.lower(x).replace(';', ',')) == col.lower().replace(';', ',')].iloc[0]['scat_category']\n",
    "    sub_sector = sic_scat_map_df[sic_scat_map_df['sic_category'].apply(lambda x: str.lower(x).replace(';', ',')) == col.lower().replace(';', ',')].iloc[0]['scat_sub_category']\n",
    "    tmp = jobs_df_2010[['lsoa01cd', 'year', col]].copy().rename(columns = {col : 'jobs_count'})\n",
    "    tmp['sub_sector'] = sub_sector\n",
    "    tmp['sector'] = sector\n",
    "    final_jobs_df_2010.append(tmp)\n",
    "\n",
    "tmp = jobs_df_2010[['lsoa01cd', 'year', 'total']].rename(columns = {'total' : 'jobs_count'})\n",
    "tmp['industry'] = 'All'\n",
    "tmp = tmp[['lsoa01cd', 'year', 'industry', 'jobs_count']]\n",
    "final_jobs_df_2010 = pd.concat(final_jobs_df_2010, ignore_index = True)\n",
    "final_jobs_df_2010 = final_jobs_df_2010.groupby(['lsoa01cd','year','sub_sector','sector']).sum().reset_index()\n",
    "final_jobs_df_2010 = pd.concat([final_jobs_df_2010.groupby(['lsoa01cd', 'year', 'sub_sector']\n",
    "                        ).sum()[['jobs_count']].reset_index().rename(columns = {'sub_sector' : 'industry'}),\n",
    "                          final_jobs_df_2010.groupby(['lsoa01cd', 'year', 'sector']\n",
    "                        ).sum()[['jobs_count']].reset_index().rename(columns = {'sector' : 'industry'}),\n",
    "                          tmp])\n",
    "print(final_jobs_df_2010.shape)\n",
    "\n",
    "filtered_jobs_df_2010 = lsoa01_to_lsoa21_map.set_index('lsoa01cd').join(\n",
    "    final_jobs_df_2010.set_index('lsoa01cd')).reset_index().drop(columns = ['lsoa01cd'])\n",
    "print(filtered_jobs_df_2010.shape)\n",
    "filtered_south_jobs_df_2010 = south_lsoa01_to_lsoa21_map.set_index('lsoa01cd').join(\n",
    "    final_jobs_df_2010.set_index('lsoa01cd')).reset_index().drop(columns = ['lsoa01cd'])\n",
    "print(final_jobs_df_2010.shape)\n",
    "print(filtered_south_jobs_df_2010.shape)\n",
    "filtered_south_jobs_df_2010 = filtered_south_jobs_df_2010.groupby([\n",
    "    'lsoa11cd','lsoa21cd', 'oa21cd', 'year', 'industry']).sum().reset_index()\n",
    "print(filtered_south_jobs_df_2010.shape)\n",
    "\n",
    "print(final_pop_oa_df.shape)\n",
    "final_pop_oa_df_tmp = final_pop_oa_df.set_index('oa21cd')[['year', 'total_pop']].join(\n",
    "    lsoa11_to_lsoa21_map.set_index('oa21cd')).reset_index()\n",
    "print(final_pop_oa_df_tmp.shape)\n",
    "final_pop_oa_df_tmp = final_pop_oa_df_tmp.set_index(['lsoa21cd', 'year']).join(\n",
    "    final_pop_oa_df_tmp.groupby(['lsoa21cd', 'year']).sum()[['total_pop']].rename(\n",
    "        columns = {'total_pop' : 'lsoa_total_pop'})).reset_index()\n",
    "final_pop_oa_df_tmp['total_pop_perc'] = final_pop_oa_df_tmp['total_pop'] / final_pop_oa_df_tmp['lsoa_total_pop']\n",
    "print(final_pop_oa_df_tmp.shape)\n",
    "\n",
    "print(final_south_pop_oa_df.shape)\n",
    "final_south_pop_oa_df_tmp = final_south_pop_oa_df.set_index('oa21cd')[['year', 'total_pop']].join(\n",
    "    south_lsoa11_to_lsoa21_map.set_index('oa21cd')).reset_index()\n",
    "print(final_south_pop_oa_df_tmp.shape)\n",
    "final_south_pop_oa_df_tmp = final_south_pop_oa_df_tmp.set_index(['lsoa21cd', 'year']).join(\n",
    "    final_south_pop_oa_df_tmp.groupby(['lsoa21cd', 'year']).sum()[['total_pop']].rename(\n",
    "        columns = {'total_pop' : 'lsoa_total_pop'})).reset_index()\n",
    "final_south_pop_oa_df_tmp['total_pop_perc'] = final_south_pop_oa_df_tmp['total_pop'] / final_south_pop_oa_df_tmp['lsoa_total_pop']\n",
    "print(final_south_pop_oa_df_tmp.shape)\n",
    "\n",
    "filtered_jobs_df_2010 = filtered_jobs_df_2010.set_index(['oa21cd', 'year']\n",
    "         ).join(final_pop_oa_df_tmp.set_index(['oa21cd', 'year'])[['total_pop_perc']]).reset_index()\n",
    "filtered_jobs_df_2010 = filtered_jobs_df_2010.rename(columns = {'jobs_count' : 'lsoa_jobs_count'})\n",
    "filtered_jobs_df_2010['jobs_count'] = (filtered_jobs_df_2010['lsoa_jobs_count'] * filtered_jobs_df_2010['total_pop_perc']\n",
    "                                 ).apply(np.round)\n",
    "\n",
    "filtered_south_jobs_df_2010 = filtered_south_jobs_df_2010.set_index(['oa21cd', 'year']\n",
    "         ).join(final_south_pop_oa_df_tmp.set_index(['oa21cd', 'year'])[['total_pop_perc']]).reset_index()\n",
    "filtered_south_jobs_df_2010 = filtered_south_jobs_df_2010.rename(columns = {'jobs_count' : 'lsoa_jobs_count'})\n",
    "filtered_south_jobs_df_2010['jobs_count'] = (filtered_south_jobs_df_2010['lsoa_jobs_count'] *\n",
    "                                        filtered_south_jobs_df_2010['total_pop_perc']).apply(np.round)\n",
    "\n",
    "filtered_jobs_df_2010.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbf038-221a-4a3b-a1c8-99199e8e4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_jobs_df = pd.concat([filtered_jobs_df_2010, filtered_jobs_df[filtered_jobs_df['year'] >= 2015]],\n",
    "                            ignore_index = True)\n",
    "filtered_south_jobs_df = pd.concat([filtered_south_jobs_df_2010, filtered_south_jobs_df[filtered_south_jobs_df['year'] >= 2015]],\n",
    "                            ignore_index = True)\n",
    "filtered_jobs_df['year'] = filtered_jobs_df['year'].apply(int)\n",
    "filtered_south_jobs_df['year'] = filtered_south_jobs_df['year'].apply(int)\n",
    "filtered_jobs_df.to_pickle(\"filtered_jobs_df.pkl\")\n",
    "filtered_south_jobs_df.to_pickle(\"filtered_south_jobs_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fc77a-4387-42e9-9dda-bc699a1040f9",
   "metadata": {},
   "source": [
    "# Process CDRC House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742260c1-d54c-4af9-9db3-fbd68f3ee91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices_df = pd.read_csv(\"Data\\\\House Prices\\\\CDRC Data\\\\prices_LSOA21.csv\")\n",
    "house_prices_df = house_prices_df.rename(columns = {'lsoa21' : 'lsoa21cd'})\n",
    "south_house_prices_df = south_lsoa11_to_lsoa21_map.set_index('lsoa21cd').join(\n",
    "    house_prices_df.set_index('lsoa21cd')).reset_index()\n",
    "house_prices_df = lsoa11_to_lsoa21_map.set_index('lsoa21cd').join(\n",
    "    house_prices_df.set_index('lsoa21cd')).reset_index()\n",
    "print(len(house_prices_df['oa21cd'].unique()))\n",
    "print(len(south_house_prices_df['oa21cd'].unique()))\n",
    "final_house_prices_df = []\n",
    "final_south_house_prices_df = []\n",
    "for i in range(17):\n",
    "    year = 2007 + i\n",
    "    tmp = house_prices_df[['lsoa21cd', 'oa21cd', f'mean_sale_value_{year}', f'mean_rental_value_{year}']].copy()\n",
    "    tmp = tmp.rename(columns = {f'mean_sale_value_{year}' : 'mean_sale_value',\n",
    "                               f'mean_rental_value_{year}' : 'mean_rental_value'})\n",
    "    tmp['year'] = year\n",
    "    final_house_prices_df.append(tmp)\n",
    "\n",
    "    tmp = south_house_prices_df[['lsoa21cd', 'oa21cd', f'mean_sale_value_{year}',\n",
    "                                 f'mean_rental_value_{year}']].copy()\n",
    "    tmp = tmp.rename(columns = {f'mean_sale_value_{year}' : 'mean_sale_value',\n",
    "                               f'mean_rental_value_{year}' : 'mean_rental_value'})\n",
    "    tmp['year'] = year\n",
    "    final_south_house_prices_df.append(tmp)\n",
    "final_house_prices_df = pd.concat(final_house_prices_df, ignore_index = True)\n",
    "final_south_house_prices_df = pd.concat(final_south_house_prices_df, ignore_index = True)\n",
    "\n",
    "final_house_prices_df.to_pickle(\"final_house_prices_df.pkl\")\n",
    "final_south_house_prices_df.to_pickle(\"final_south_house_prices_df.pkl\")\n",
    "\n",
    "final_house_prices_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
